{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of csv files read:  45\n",
      "Number of csv files read:  45\n",
      "[array([[ 9.4 ,  0.57,  4.45, -0.1 ,  0.05, -0.01],\n",
      "       [ 9.39,  0.62,  4.5 , -0.1 ,  0.05, -0.02],\n",
      "       [ 9.35,  0.61,  4.36, -0.11,  0.05, -0.01],\n",
      "       ...,\n",
      "       [ 9.39,  0.38,  4.4 , -0.12,  0.06, -0.01],\n",
      "       [ 9.41,  0.38,  4.37, -0.12,  0.06, -0.01],\n",
      "       [ 9.4 ,  0.38,  4.36, -0.12,  0.06, -0.01]]), array([[ 9.38,  0.37,  4.36, -0.1 ,  0.06, -0.02],\n",
      "       [ 9.39,  0.37,  4.41, -0.12,  0.07, -0.01],\n",
      "       [ 9.39,  0.41,  4.44, -0.11,  0.05, -0.  ],\n",
      "       ...,\n",
      "       [ 9.39,  0.25,  4.4 , -0.11,  0.05, -0.01],\n",
      "       [ 9.39,  0.23,  4.42, -0.13,  0.05, -0.01],\n",
      "       [ 9.39,  0.23,  4.42, -0.13,  0.04, -0.01]]), array([[ 9.27, -1.57,  4.38, -0.1 ,  0.06, -0.01],\n",
      "       [ 9.25, -1.54,  4.4 , -0.11,  0.04, -0.02],\n",
      "       [ 9.2 , -1.55,  4.35, -0.11,  0.06, -0.01],\n",
      "       ...,\n",
      "       [ 9.14, -1.52,  4.6 , -0.12,  0.05, -0.01],\n",
      "       [ 9.15, -1.57,  4.65, -0.11,  0.05, -0.01],\n",
      "       [ 9.14, -1.52,  4.64, -0.12,  0.04, -0.01]]), array([[ 9.13, -1.53,  4.63, -0.12,  0.05, -0.01],\n",
      "       [ 9.12, -1.55,  4.63, -0.12,  0.06, -0.01],\n",
      "       [ 9.17, -1.55,  4.65, -0.11,  0.04, -0.01],\n",
      "       ...,\n",
      "       [ 9.09, -1.77,  4.65, -0.12,  0.04, -0.01],\n",
      "       [ 9.06, -1.78,  4.63, -0.12,  0.03, -0.01],\n",
      "       [ 9.06, -1.78,  4.65, -0.12,  0.04, -0.01]]), array([[ 9.11, -1.79,  4.63, -0.11,  0.05, -0.01],\n",
      "       [ 9.08, -1.78,  4.62, -0.13,  0.04, -0.01],\n",
      "       [ 9.1 , -1.79,  4.63, -0.13,  0.03, -0.01],\n",
      "       ...,\n",
      "       [ 9.06, -2.05,  4.47, -0.11,  0.07, -0.01],\n",
      "       [ 9.07, -2.06,  4.51, -0.11,  0.07, -0.01],\n",
      "       [ 9.1 , -2.07,  4.54, -0.12,  0.06, -0.01]]), array([[ 9.07, -2.08,  4.5 , -0.11,  0.05, -0.02],\n",
      "       [ 9.05, -2.09,  4.45, -0.11,  0.08, -0.02],\n",
      "       [ 9.06, -2.07,  4.53, -0.11,  0.08, -0.01],\n",
      "       ...,\n",
      "       [ 9.03, -2.23,  4.51, -0.1 ,  0.05, -0.  ],\n",
      "       [ 9.02, -2.18,  4.53, -0.11,  0.05, -0.01],\n",
      "       [ 9.03, -2.19,  4.47, -0.1 ,  0.05, -0.01]]), array([[ 9.04, -2.19,  4.55, -0.11,  0.06, -0.01],\n",
      "       [ 9.07, -2.19,  4.56, -0.11,  0.05, -0.01],\n",
      "       [ 9.02, -2.19,  4.5 , -0.11,  0.04, -0.01],\n",
      "       ...,\n",
      "       [ 8.97, -2.28,  4.52, -0.11,  0.05, -0.01],\n",
      "       [ 8.94, -2.31,  4.5 , -0.11,  0.06, -0.01],\n",
      "       [ 8.99, -2.31,  4.55, -0.12,  0.05, -0.01]]), array([[ 9.41,  0.23,  4.4 , -0.13,  0.03, -0.01],\n",
      "       [ 9.38,  0.22,  4.37, -0.13,  0.04, -0.01],\n",
      "       [ 9.42,  0.19,  4.39, -0.13,  0.05, -0.01],\n",
      "       ...,\n",
      "       [ 9.39,  0.08,  4.41, -0.13,  0.05, -0.02],\n",
      "       [ 9.42,  0.07,  4.41, -0.13,  0.05, -0.01],\n",
      "       [ 9.39,  0.05,  4.43, -0.12,  0.05, -0.01]]), array([[ 9.4 ,  0.07,  4.42, -0.12,  0.05, -0.01],\n",
      "       [ 9.42,  0.06,  4.39, -0.12,  0.05, -0.01],\n",
      "       [ 9.4 ,  0.06,  4.4 , -0.12,  0.05, -0.01],\n",
      "       ...,\n",
      "       [ 9.42, -0.04,  4.46, -0.13,  0.04, -0.01],\n",
      "       [ 9.33, -0.01,  4.41, -0.13,  0.04, -0.01],\n",
      "       [ 9.39, -0.08,  4.37, -0.13,  0.05, -0.01]]), array([[ 9.39, -0.05,  4.41, -0.12,  0.05, -0.01],\n",
      "       [ 9.39, -0.04,  4.43, -0.12,  0.05, -0.01],\n",
      "       [ 9.42, -0.03,  4.43, -0.13,  0.05, -0.01],\n",
      "       ...,\n",
      "       [ 9.37, -0.09,  4.42, -0.12,  0.04, -0.01],\n",
      "       [ 9.36, -0.06,  4.42, -0.11,  0.06, -0.01],\n",
      "       [ 9.39, -0.11,  4.45, -0.12,  0.05, -0.01]]), array([[ 9.22, -1.33,  4.56, -0.11,  0.06, -0.01],\n",
      "       [ 9.22, -1.33,  4.54, -0.11,  0.06, -0.01],\n",
      "       [ 9.2 , -1.31,  4.48, -0.11,  0.07, -0.01],\n",
      "       ...,\n",
      "       [ 9.28, -1.58,  4.3 , -0.11,  0.06, -0.02],\n",
      "       [ 9.25, -1.54,  4.37, -0.11,  0.06, -0.01],\n",
      "       [ 9.25, -1.55,  4.38, -0.11,  0.06, -0.  ]]), array([[ 9.28,  0.08,  4.68, -0.12,  0.05, -0.  ],\n",
      "       [ 9.32,  0.04,  4.66, -0.12,  0.04, -0.  ],\n",
      "       [ 9.33,  0.06,  4.61, -0.11,  0.04, -0.01],\n",
      "       ...,\n",
      "       [ 9.35, -0.16,  4.59, -0.11,  0.05, -0.01],\n",
      "       [ 9.32, -0.14,  4.53, -0.11,  0.05, -0.01],\n",
      "       [ 9.28, -0.19,  4.57, -0.11,  0.06, -0.01]]), array([[ 9.35, -0.19,  4.62, -0.11,  0.06, -0.01],\n",
      "       [ 9.33, -0.17,  4.6 , -0.11,  0.05, -0.01],\n",
      "       [ 9.31, -0.13,  4.55, -0.11,  0.04, -0.01],\n",
      "       ...,\n",
      "       [ 9.27, -0.26,  4.56, -0.11,  0.07, -0.01],\n",
      "       [ 9.33, -0.27,  4.59, -0.11,  0.08, -0.01],\n",
      "       [ 9.33, -0.28,  4.63, -0.11,  0.06, -0.01]]), array([[ 9.29, -0.26,  4.56, -0.11,  0.06, -0.01],\n",
      "       [ 9.29, -0.25,  4.54, -0.1 ,  0.07, -0.01],\n",
      "       [ 9.3 , -0.26,  4.58, -0.11,  0.07, -0.01],\n",
      "       ...,\n",
      "       [ 9.43, -0.45,  4.3 , -0.12,  0.04,  0.  ],\n",
      "       [ 9.43, -0.45,  4.29, -0.11,  0.05, -0.01],\n",
      "       [ 9.4 , -0.47,  4.27, -0.11,  0.05, -0.01]]), array([[ 9.39, -0.46,  4.3 , -0.11,  0.06, -0.01],\n",
      "       [ 9.45, -0.47,  4.34, -0.12,  0.07, -0.01],\n",
      "       [ 9.44, -0.45,  4.35, -0.12,  0.05, -0.01],\n",
      "       ...,\n",
      "       [ 9.25, -0.49,  4.63, -0.11,  0.05, -0.01],\n",
      "       [ 9.24, -0.52,  4.66, -0.1 ,  0.07, -0.01],\n",
      "       [ 9.23, -0.49,  4.71, -0.11,  0.06, -0.01]]), array([[ 9.39,  0.07,  4.38, -0.12,  0.03, -0.01],\n",
      "       [ 9.4 ,  0.03,  4.36, -0.12,  0.02, -0.01],\n",
      "       [ 9.44, -0.01,  4.34, -0.1 ,  0.04, -0.01],\n",
      "       ...,\n",
      "       [ 9.37, -0.15,  4.52, -0.11,  0.05, -0.01],\n",
      "       [ 9.36, -0.16,  4.5 , -0.11,  0.05, -0.01],\n",
      "       [ 9.35, -0.15,  4.52, -0.11,  0.07, -0.01]]), array([[ 9.34, -0.14,  4.52, -0.11,  0.06, -0.01],\n",
      "       [ 9.37, -0.13,  4.51, -0.11,  0.07, -0.01],\n",
      "       [ 9.36, -0.16,  4.53, -0.11,  0.06, -0.01],\n",
      "       ...,\n",
      "       [ 9.31, -0.23,  4.61, -0.11,  0.05, -0.01],\n",
      "       [ 9.31, -0.26,  4.63, -0.12,  0.04, -0.01],\n",
      "       [ 9.33, -0.27,  4.51, -0.11,  0.05, -0.01]]), array([[ 9.05,  0.03,  5.02, -0.1 ,  0.06, -0.01],\n",
      "       [ 9.06,  0.07,  5.06, -0.1 ,  0.07, -0.01],\n",
      "       [ 9.08,  0.04,  5.07, -0.11,  0.06, -0.  ],\n",
      "       ...,\n",
      "       [ 8.95, -0.49,  5.28, -0.11,  0.06, -0.01],\n",
      "       [ 8.92, -0.47,  5.27, -0.11,  0.04, -0.01],\n",
      "       [ 8.94, -0.51,  5.24, -0.11,  0.05, -0.01]]), array([[ 8.92, -0.49,  5.27, -0.1 ,  0.06, -0.01],\n",
      "       [ 8.94, -0.53,  5.28, -0.11,  0.05, -0.01],\n",
      "       [ 8.93, -0.47,  5.26, -0.1 ,  0.06, -0.01],\n",
      "       ...,\n",
      "       [ 8.94, -0.61,  5.24, -0.11,  0.06, -0.02],\n",
      "       [ 8.92, -0.61,  5.27, -0.11,  0.06, -0.01],\n",
      "       [ 8.94, -0.59,  5.29, -0.11,  0.06, -0.01]]), array([[ 8.92, -0.61,  5.29, -0.11,  0.05, -0.02],\n",
      "       [ 8.9 , -0.61,  5.26, -0.11,  0.05, -0.01],\n",
      "       [ 8.89, -0.63,  5.29, -0.11,  0.06, -0.01],\n",
      "       ...,\n",
      "       [ 8.95, -0.77,  5.11, -0.12,  0.07, -0.  ],\n",
      "       [ 9.01, -0.8 ,  5.11, -0.11,  0.08, -0.01],\n",
      "       [ 8.98, -0.79,  5.16, -0.11,  0.08, -0.01]]), array([[ 8.94, -0.77,  5.17, -0.11,  0.07, -0.01],\n",
      "       [ 8.96, -0.79,  5.11, -0.1 ,  0.08, -0.01],\n",
      "       [ 8.95, -0.78,  5.16, -0.11,  0.09, -0.02],\n",
      "       ...,\n",
      "       [ 8.9 , -0.91,  5.25, -0.11,  0.02, -0.01],\n",
      "       [ 8.92, -0.94,  5.2 , -0.1 ,  0.03, -0.02],\n",
      "       [ 8.91, -0.91,  5.24, -0.12,  0.02, -0.01]]), array([[ 8.93, -0.94,  5.2 , -0.12,  0.02, -0.01],\n",
      "       [ 8.92, -0.94,  5.18, -0.12,  0.02, -0.01],\n",
      "       [ 8.94, -0.94,  5.15, -0.11,  0.03, -0.01],\n",
      "       ...,\n",
      "       [ 8.93, -1.08,  5.18, -0.12,  0.02, -0.01],\n",
      "       [ 8.92, -1.12,  5.09, -0.11,  0.04, -0.01],\n",
      "       [ 8.92, -1.1 ,  5.17, -0.11,  0.05, -0.01]]), array([[ 8.96, -1.14,  5.15, -0.11,  0.04, -0.01],\n",
      "       [ 8.93, -1.1 ,  5.12, -0.12,  0.04, -0.01],\n",
      "       [ 8.92, -1.1 ,  5.13, -0.12,  0.04, -0.01],\n",
      "       ...,\n",
      "       [ 8.86, -1.21,  5.25, -0.11,  0.05, -0.01],\n",
      "       [ 8.85, -1.21,  5.26, -0.11,  0.05, -0.01],\n",
      "       [ 8.85, -1.22,  5.29, -0.11,  0.06, -0.01]]), array([[ 8.85, -1.22,  5.29, -0.11,  0.05, -0.01],\n",
      "       [ 8.83, -1.22,  5.26, -0.11,  0.05, -0.02],\n",
      "       [ 8.83, -1.23,  5.24, -0.11,  0.05, -0.01],\n",
      "       ...,\n",
      "       [ 8.83, -1.34,  5.27, -0.11,  0.06, -0.01],\n",
      "       [ 8.86, -1.35,  5.21, -0.11,  0.06, -0.01],\n",
      "       [ 8.85, -1.33,  5.25, -0.11,  0.06, -0.01]]), array([[ 8.83, -1.34,  5.26, -0.11,  0.06, -0.01],\n",
      "       [ 8.84, -1.36,  5.24, -0.11,  0.06, -0.01],\n",
      "       [ 8.84, -1.34,  5.25, -0.11,  0.05, -0.01],\n",
      "       ...,\n",
      "       [ 8.77, -1.4 ,  5.28, -0.11,  0.06, -0.  ],\n",
      "       [ 8.82, -1.48,  5.29, -0.11,  0.05, -0.01],\n",
      "       [ 8.8 , -1.4 ,  5.25, -0.11,  0.05, -0.01]]), array([[ 8.8 , -1.43,  5.23, -0.1 ,  0.05, -0.01],\n",
      "       [ 8.8 , -1.45,  5.27, -0.11,  0.06, -0.01],\n",
      "       [ 8.82, -1.44,  5.28, -0.11,  0.05, -0.01],\n",
      "       ...,\n",
      "       [ 8.79, -1.57,  5.24, -0.12,  0.04, -0.01],\n",
      "       [ 8.79, -1.56,  5.26, -0.12,  0.03, -0.01],\n",
      "       [ 8.82, -1.57,  5.25, -0.12,  0.03, -0.01]]), array([[ 8.8 , -1.57,  5.21, -0.12,  0.03, -0.01],\n",
      "       [ 8.8 , -1.54,  5.22, -0.11,  0.03, -0.01],\n",
      "       [ 8.82, -1.58,  5.19, -0.11,  0.03, -0.01],\n",
      "       ...,\n",
      "       [ 8.77, -1.6 ,  5.33, -0.11,  0.05, -0.01],\n",
      "       [ 8.76, -1.58,  5.26, -0.11,  0.05, -0.01],\n",
      "       [ 8.75, -1.57,  5.33, -0.11,  0.05, -0.01]]), array([[ 9.31, -0.23,  4.59, -0.12,  0.06, -0.02],\n",
      "       [ 9.29, -0.22,  4.63, -0.12,  0.06, -0.01],\n",
      "       [ 9.33, -0.27,  4.55, -0.11,  0.06, -0.  ],\n",
      "       ...,\n",
      "       [ 9.31, -0.3 ,  4.51, -0.11,  0.02, -0.01],\n",
      "       [ 9.31, -0.29,  4.49, -0.1 ,  0.03, -0.01],\n",
      "       [ 9.34, -0.32,  4.47, -0.11,  0.04, -0.01]]), array([[ 8.86, -0.91,  5.42, -0.1 ,  0.  , -0.01],\n",
      "       [ 8.83, -0.89,  5.29, -0.13,  0.02,  0.  ],\n",
      "       [ 8.76, -0.9 ,  5.32, -0.2 ,  0.05, -0.01],\n",
      "       ...,\n",
      "       [ 8.71, -1.73,  5.31, -0.11,  0.05, -0.01],\n",
      "       [ 8.72, -1.73,  5.31, -0.11,  0.05, -0.01],\n",
      "       [ 8.72, -1.75,  5.29, -0.11,  0.06, -0.01]]), array([[ 8.68, -1.71,  5.32, -0.11,  0.07, -0.01],\n",
      "       [ 8.69, -1.72,  5.38, -0.12,  0.06, -0.  ],\n",
      "       [ 8.75, -1.73,  5.33, -0.11,  0.04, -0.01],\n",
      "       ...,\n",
      "       [ 8.74, -1.8 ,  5.2 , -0.12,  0.05, -0.01],\n",
      "       [ 8.8 , -1.8 ,  5.2 , -0.11,  0.06, -0.01],\n",
      "       [ 8.77, -1.77,  5.21, -0.12,  0.06, -0.01]]), array([[ 8.74, -1.77,  5.19, -0.11,  0.06, -0.01],\n",
      "       [ 8.74, -1.81,  5.17, -0.11,  0.07, -0.01],\n",
      "       [ 8.78, -1.8 ,  5.22, -0.11,  0.07, -0.01],\n",
      "       ...,\n",
      "       [ 8.67, -1.84,  5.29, -0.11,  0.03, -0.02],\n",
      "       [ 8.67, -1.81,  5.34, -0.12,  0.05, -0.01],\n",
      "       [ 8.7 , -1.86,  5.32, -0.1 ,  0.04, -0.01]]), array([[ 8.69, -1.81,  5.36, -0.11,  0.03, -0.01],\n",
      "       [ 8.7 , -1.82,  5.32, -0.11,  0.04, -0.01],\n",
      "       [ 8.69, -1.84,  5.31, -0.11,  0.04, -0.01],\n",
      "       ...,\n",
      "       [ 8.71, -1.88,  5.31, -0.11,  0.05, -0.01],\n",
      "       [ 8.72, -1.86,  5.35, -0.11,  0.06, -0.01],\n",
      "       [ 8.7 , -1.88,  5.3 , -0.11,  0.05, -0.01]]), array([[ 8.71, -1.89,  5.3 , -0.1 ,  0.03, -0.02],\n",
      "       [ 8.68, -1.87,  5.28, -0.11,  0.06, -0.01],\n",
      "       [ 8.68, -1.88,  5.31, -0.12,  0.05, -0.  ],\n",
      "       ...,\n",
      "       [ 8.79, -1.94,  5.14, -0.11,  0.04, -0.01],\n",
      "       [ 8.81, -1.95,  5.14, -0.1 ,  0.03, -0.01],\n",
      "       [ 8.77, -1.92,  5.11, -0.11,  0.03, -0.01]]), array([[ 8.77, -1.92,  5.08, -0.11,  0.03, -0.01],\n",
      "       [ 8.78, -1.94,  5.05, -0.11,  0.05, -0.01],\n",
      "       [ 8.82, -1.96,  5.07, -0.11,  0.05, -0.01],\n",
      "       ...,\n",
      "       [ 8.79, -2.04,  5.14, -0.11,  0.03, -0.01],\n",
      "       [ 8.76, -2.02,  5.13, -0.11,  0.01, -0.01],\n",
      "       [ 8.76, -2.01,  5.09, -0.1 ,  0.04, -0.02]]), array([[ 8.74, -2.03,  5.1 , -0.11,  0.03, -0.01],\n",
      "       [ 8.79, -2.04,  5.11, -0.11,  0.03, -0.01],\n",
      "       [ 8.78, -2.  ,  5.1 , -0.11,  0.03, -0.01],\n",
      "       ...,\n",
      "       [ 8.74, -2.1 ,  5.19, -0.11,  0.06, -0.01],\n",
      "       [ 8.71, -2.1 ,  5.16, -0.11,  0.06, -0.01],\n",
      "       [ 8.72, -2.08,  5.14, -0.1 ,  0.05, -0.01]]), array([[ 8.69, -2.08,  5.12, -0.11,  0.07, -0.01],\n",
      "       [ 8.67, -2.06,  5.2 , -0.11,  0.07, -0.01],\n",
      "       [ 8.75, -2.12,  5.2 , -0.11,  0.05, -0.  ],\n",
      "       ...,\n",
      "       [ 8.78, -2.16,  4.97, -0.11,  0.03, -0.01],\n",
      "       [ 8.78, -2.18,  4.98, -0.11,  0.03, -0.01],\n",
      "       [ 8.82, -2.17,  5.  , -0.11,  0.03, -0.01]]), array([[ 8.8 , -2.16,  5.  , -0.1 ,  0.03, -0.02],\n",
      "       [ 8.8 , -2.18,  4.95, -0.1 ,  0.04, -0.01],\n",
      "       [ 8.77, -2.15,  4.95, -0.11,  0.03, -0.01],\n",
      "       ...,\n",
      "       [ 8.68, -2.21,  5.14, -0.1 ,  0.08, -0.02],\n",
      "       [ 8.68, -2.2 ,  5.17, -0.1 ,  0.09, -0.  ],\n",
      "       [ 8.69, -2.27,  5.18, -0.1 ,  0.06, -0.01]]), array([[ 8.68, -2.19,  5.18, -0.1 ,  0.06, -0.01],\n",
      "       [ 8.66, -2.23,  5.11, -0.1 ,  0.05, -0.01],\n",
      "       [ 8.68, -2.24,  5.18, -0.11,  0.06, -0.01],\n",
      "       ...,\n",
      "       [ 8.68, -2.27,  5.15, -0.11,  0.04, -0.01],\n",
      "       [ 8.68, -2.26,  5.18, -0.11,  0.03, -0.01],\n",
      "       [ 8.66, -2.26,  5.17, -0.11,  0.02, -0.01]]), array([[ 9.32, -0.31,  4.47, -0.12,  0.03, -0.01],\n",
      "       [ 9.34, -0.32,  4.47, -0.11,  0.04, -0.01],\n",
      "       [ 9.34, -0.35,  4.4 , -0.11,  0.06, -0.01],\n",
      "       ...,\n",
      "       [ 9.28, -0.48,  4.66, -0.11,  0.05, -0.02],\n",
      "       [ 9.26, -0.41,  4.63, -0.12,  0.04, -0.01],\n",
      "       [ 9.24, -0.44,  4.65, -0.12,  0.05, -0.01]]), array([[ 9.3 , -0.48,  4.65, -0.11,  0.05, -0.01],\n",
      "       [ 9.29, -0.43,  4.65, -0.11,  0.04, -0.02],\n",
      "       [ 9.28, -0.42,  4.6 , -0.12,  0.03, -0.01],\n",
      "       ...,\n",
      "       [ 9.29, -0.53,  4.57, -0.12,  0.07, -0.01],\n",
      "       [ 9.3 , -0.59,  4.48, -0.1 ,  0.1 , -0.02],\n",
      "       [ 9.28, -0.54,  4.56, -0.11,  0.09, -0.02]]), array([[ 9.25, -0.51,  4.61, -0.11,  0.08, -0.01],\n",
      "       [ 9.28, -0.52,  4.64, -0.1 ,  0.08, -0.  ],\n",
      "       [ 9.26, -0.54,  4.62, -0.1 ,  0.06, -0.01],\n",
      "       ...,\n",
      "       [ 9.23, -0.67,  4.66, -0.11,  0.05, -0.01],\n",
      "       [ 9.22, -0.65,  4.65, -0.11,  0.06, -0.01],\n",
      "       [ 9.22, -0.66,  4.68, -0.11,  0.05, -0.01]]), array([[ 9.24, -0.66,  4.69, -0.11,  0.05, -0.01],\n",
      "       [ 9.24, -0.67,  4.64, -0.1 ,  0.06, -0.01],\n",
      "       [ 9.23, -0.66,  4.7 , -0.11,  0.06, -0.01],\n",
      "       ...,\n",
      "       [ 9.27, -0.78,  4.56, -0.11,  0.05, -0.02],\n",
      "       [ 9.28, -0.79,  4.58, -0.11,  0.05, -0.02],\n",
      "       [ 9.26, -0.79,  4.56, -0.11,  0.04, -0.02]]), array([[ 9.26, -0.78,  4.57, -0.11,  0.05, -0.02],\n",
      "       [ 9.28, -0.78,  4.54, -0.11,  0.05, -0.02],\n",
      "       [ 9.24, -0.77,  4.57, -0.11,  0.05, -0.02],\n",
      "       ...,\n",
      "       [ 9.19, -0.87,  4.7 , -0.11,  0.05, -0.02],\n",
      "       [ 9.2 , -0.91,  4.68, -0.11,  0.05, -0.01],\n",
      "       [ 9.19, -0.89,  4.66, -0.11,  0.06, -0.01]]), array([[ 9.19, -0.92,  4.7 , -0.11,  0.06, -0.01],\n",
      "       [ 9.24, -0.9 ,  4.69, -0.11,  0.05, -0.01],\n",
      "       [ 9.18, -0.88,  4.66, -0.11,  0.05, -0.01],\n",
      "       ...,\n",
      "       [ 9.17, -0.98,  4.71, -0.11,  0.06, -0.01],\n",
      "       [ 9.2 , -0.98,  4.74, -0.11,  0.06, -0.01],\n",
      "       [ 9.18, -0.97,  4.69, -0.11,  0.05, -0.01]]), array([[ 9.16, -0.97,  4.68, -0.11,  0.04, -0.01],\n",
      "       [ 9.17, -0.97,  4.67, -0.11,  0.06, -0.01],\n",
      "       [ 9.17, -1.  ,  4.72, -0.11,  0.06, -0.01],\n",
      "       ...,\n",
      "       [ 9.15, -1.05,  4.73, -0.12,  0.05, -0.02],\n",
      "       [ 9.17, -1.03,  4.71, -0.11,  0.05, -0.02],\n",
      "       [ 9.17, -1.04,  4.75, -0.11,  0.05, -0.01]])]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"data/output2\"\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "fileNames = os.listdir(data_path)\n",
    "\n",
    "tflite_model_name = \"sleep_tracking_model\"\n",
    "c_model_name = \"sleep_tracking_model\"\n",
    "\n",
    "\n",
    "for fileName in fileNames:\n",
    "    if fileName.endswith(\".csv\"):\n",
    "        filePath = os.path.join(data_path, fileName)\n",
    "        fileName = fileName.split('.')[0][:2]\n",
    "        if fileName == \"AN\":\n",
    "            Y.append(1)\n",
    "        elif fileName == \"NM\":\n",
    "            Y.append(0)\n",
    "\n",
    "        df = pd.read_csv(filePath)\n",
    "        df = df.drop(labels=\"STT\", axis=1)\n",
    "        X.append(df.values)\n",
    "\n",
    "print(\"Number of csv files read: \", len(X))\n",
    "print(\"Number of csv files read: \", len(Y))\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 36\n",
      "Number of samples in test set: 9\n",
      "Min of train: 0.0\n",
      "Min of test: 0.0\n",
      "(2000, 6)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y) \n",
    "\n",
    "print(\"Number of samples in training set:\", xTrain.shape[0])\n",
    "print(\"Number of samples in test set:\", xTest.shape[0])\n",
    "\n",
    "xTrain -= np.min(xTrain)\n",
    "xTest -= np.min(xTest)\n",
    "\n",
    "print(\"Min of train:\", np.min(xTrain))\n",
    "print(\"Min of test:\", np.min(xTest))\n",
    "\n",
    "print(xTrain[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_59 (Conv1D)          (None, 1996, 1)           31        \n",
      "                                                                 \n",
      " average_pooling1d_51 (Aver  (None, 665, 1)            0         \n",
      " agePooling1D)                                                   \n",
      "                                                                 \n",
      " conv1d_60 (Conv1D)          (None, 663, 1)            4         \n",
      "                                                                 \n",
      " average_pooling1d_52 (Aver  (None, 221, 1)            0         \n",
      " agePooling1D)                                                   \n",
      "                                                                 \n",
      " conv1d_61 (Conv1D)          (None, 219, 1)            4         \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 219)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 128)               28160     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28328 (110.66 KB)\n",
      "Trainable params: 28328 (110.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, MaxPool1D, AveragePooling1D\n",
    "\n",
    "inputShape = (2000, 6)\n",
    "filters = 1\n",
    "kernelSize = 6\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(filters = filters, kernel_size = kernelSize, input_shape=inputShape, activation=\"sigmoid\"))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv1D(filters = filters, kernel_size = kernelSize, activation=\"sigmoid\"))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv1D(filters = filters, kernel_size = kernelSize, activation=\"sigmoid\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.6614 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6670 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6521 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6259 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6616 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6629 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6194 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6160 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6296 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6556 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6156 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6351 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6305 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6695 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6292 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6494 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6472 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6374 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6617 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6576 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6121 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6686 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6442 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6300 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6440 - accuracy: 0.6667 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6758 - accuracy: 0.6667 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6650 - accuracy: 0.6667 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6938 - accuracy: 0.6667 - val_loss: 0.6420 - val_accuracy: 0.6667\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6378 - accuracy: 0.6667 - val_loss: 0.6431 - val_accuracy: 0.6667\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6673 - accuracy: 0.6667 - val_loss: 0.6431 - val_accuracy: 0.6667\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6635 - accuracy: 0.6667 - val_loss: 0.6416 - val_accuracy: 0.6667\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6670 - accuracy: 0.6667 - val_loss: 0.6396 - val_accuracy: 0.6667\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6278 - accuracy: 0.6667 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6303 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6141 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6335 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6449 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6285 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6695 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6220 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6617 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6459 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6335 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6312 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6238 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6393 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6277 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6465 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6557 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6372 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.6241 - accuracy: 0.6667 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6928 - accuracy: 0.6667 - val_loss: 0.6398 - val_accuracy: 0.6667\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6206 - accuracy: 0.6667 - val_loss: 0.6406 - val_accuracy: 0.6667\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6415 - accuracy: 0.6667 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6553 - accuracy: 0.6667 - val_loss: 0.6421 - val_accuracy: 0.6667\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6515 - accuracy: 0.6667 - val_loss: 0.6428 - val_accuracy: 0.6667\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6658 - accuracy: 0.6667 - val_loss: 0.6439 - val_accuracy: 0.6667\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6240 - accuracy: 0.6667 - val_loss: 0.6455 - val_accuracy: 0.6667\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6446 - accuracy: 0.6667 - val_loss: 0.6466 - val_accuracy: 0.6667\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6442 - accuracy: 0.6667 - val_loss: 0.6479 - val_accuracy: 0.6667\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6405 - accuracy: 0.6667 - val_loss: 0.6490 - val_accuracy: 0.6667\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6465 - accuracy: 0.6667 - val_loss: 0.6478 - val_accuracy: 0.6667\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6893 - accuracy: 0.6667 - val_loss: 0.6448 - val_accuracy: 0.6667\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6574 - accuracy: 0.6667 - val_loss: 0.6420 - val_accuracy: 0.6667\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6399 - accuracy: 0.6667 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6556 - accuracy: 0.6667 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6324 - accuracy: 0.6667 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6313 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6291 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6380 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6523 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6562 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6210 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6418 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6461 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6664 - accuracy: 0.6667 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6422 - accuracy: 0.6667 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6342 - accuracy: 0.6667 - val_loss: 0.6401 - val_accuracy: 0.6667\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6529 - accuracy: 0.6667 - val_loss: 0.6405 - val_accuracy: 0.6667\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6444 - accuracy: 0.6667 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6316 - accuracy: 0.6667 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6749 - accuracy: 0.6667 - val_loss: 0.6416 - val_accuracy: 0.6667\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6381 - accuracy: 0.6667 - val_loss: 0.6417 - val_accuracy: 0.6667\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6247 - accuracy: 0.6667 - val_loss: 0.6416 - val_accuracy: 0.6667\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6461 - accuracy: 0.6389 - val_loss: 0.6415 - val_accuracy: 0.6667\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6160 - accuracy: 0.6667 - val_loss: 0.6417 - val_accuracy: 0.6667\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6462 - accuracy: 0.6389 - val_loss: 0.6418 - val_accuracy: 0.6667\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6339 - accuracy: 0.6667 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6224 - accuracy: 0.6667 - val_loss: 0.6411 - val_accuracy: 0.6667\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6651 - accuracy: 0.6667 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6404 - accuracy: 0.6667 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6592 - accuracy: 0.6667 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6692 - accuracy: 0.6667 - val_loss: 0.6409 - val_accuracy: 0.6667\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6315 - accuracy: 0.6667 - val_loss: 0.6409 - val_accuracy: 0.6667\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.6450 - accuracy: 0.6667 - val_loss: 0.6412 - val_accuracy: 0.6667\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6698 - accuracy: 0.6667 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6398 - accuracy: 0.6667 - val_loss: 0.6409 - val_accuracy: 0.6667\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6444 - accuracy: 0.6667 - val_loss: 0.6405 - val_accuracy: 0.6667\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6312 - accuracy: 0.6667 - val_loss: 0.6401 - val_accuracy: 0.6667\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6483 - accuracy: 0.6667 - val_loss: 0.6396 - val_accuracy: 0.6667\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6433 - accuracy: 0.6667 - val_loss: 0.6389 - val_accuracy: 0.6667\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6449 - accuracy: 0.6667 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6351 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6497 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6509 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6175 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6090 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6305 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6295 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6634 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6294 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6483 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6235 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6415 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6492 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6401 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6370 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6803 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6506 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6481 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6524 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6521 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6383 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6712 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6354 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6570 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6298 - accuracy: 0.6667 - val_loss: 0.6392 - val_accuracy: 0.6667\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6552 - accuracy: 0.6667 - val_loss: 0.6403 - val_accuracy: 0.6667\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6368 - accuracy: 0.6667 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6537 - accuracy: 0.6667 - val_loss: 0.6422 - val_accuracy: 0.6667\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6435 - accuracy: 0.6667 - val_loss: 0.6424 - val_accuracy: 0.6667\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6492 - accuracy: 0.6667 - val_loss: 0.6424 - val_accuracy: 0.6667\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6487 - accuracy: 0.6667 - val_loss: 0.6417 - val_accuracy: 0.6667\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6459 - accuracy: 0.6667 - val_loss: 0.6405 - val_accuracy: 0.6667\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6632 - accuracy: 0.6667 - val_loss: 0.6392 - val_accuracy: 0.6667\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6360 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6493 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6462 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6606 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6507 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6227 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6508 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6414 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6491 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6265 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6545 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6561 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6200 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6117 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6294 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6260 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6372 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6235 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6428 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6443 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6516 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6227 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6300 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6657 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6387 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6553 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6205 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6217 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6254 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6531 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6259 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6486 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6385 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6402 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6469 - accuracy: 0.6667 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6128 - accuracy: 0.6667 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6357 - accuracy: 0.6667 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6188 - accuracy: 0.6667 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6695 - accuracy: 0.6667 - val_loss: 0.6409 - val_accuracy: 0.6667\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6444 - accuracy: 0.6667 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6507 - accuracy: 0.6667 - val_loss: 0.6415 - val_accuracy: 0.6667\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6329 - accuracy: 0.6667 - val_loss: 0.6416 - val_accuracy: 0.6667\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6497 - accuracy: 0.6667 - val_loss: 0.6416 - val_accuracy: 0.6667\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7007 - accuracy: 0.6667 - val_loss: 0.6414 - val_accuracy: 0.6667\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6311 - accuracy: 0.6667 - val_loss: 0.6416 - val_accuracy: 0.6667\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6524 - accuracy: 0.6667 - val_loss: 0.6414 - val_accuracy: 0.6667\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6416 - accuracy: 0.6667 - val_loss: 0.6407 - val_accuracy: 0.6667\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6327 - accuracy: 0.6667 - val_loss: 0.6403 - val_accuracy: 0.6667\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6312 - accuracy: 0.6667 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6507 - accuracy: 0.6667 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6412 - accuracy: 0.6667 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6681 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6157 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6166 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6561 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6512 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6570 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6451 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6394 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6131 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6777 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6767 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6315 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6129 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6269 - accuracy: 0.6667 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6497 - accuracy: 0.6667 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6407 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6454 - accuracy: 0.6667 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6516 - accuracy: 0.6667 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6136 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6462 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6408 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6180 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6346 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6381 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6345 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6439 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6349 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6653 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6626 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6516 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6506 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6393 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6133 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6304 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6449 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6696 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6221 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6357 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6337 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6276 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6533 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6661 - accuracy: 0.6667 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6564 - accuracy: 0.6667 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6211 - accuracy: 0.6667 - val_loss: 0.6392 - val_accuracy: 0.6667\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6262 - accuracy: 0.6667 - val_loss: 0.6397 - val_accuracy: 0.6667\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6512 - accuracy: 0.6667 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6618 - accuracy: 0.6667 - val_loss: 0.6403 - val_accuracy: 0.6667\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6652 - accuracy: 0.6667 - val_loss: 0.6404 - val_accuracy: 0.6667\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6316 - accuracy: 0.6667 - val_loss: 0.6401 - val_accuracy: 0.6667\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6330 - accuracy: 0.6667 - val_loss: 0.6396 - val_accuracy: 0.6667\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6403 - accuracy: 0.6667 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6587 - accuracy: 0.6667 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6249 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6499 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6387 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6408 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6564 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6552 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6255 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6537 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6350 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6246 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6346 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6508 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6388 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6406 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6528 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6518 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6440 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6578 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6365 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6561 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6500 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6238 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6477 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6710 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6422 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6021 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6304 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6353 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6305 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6481 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6282 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6437 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6283 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6358 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6295 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6056 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6395 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6323 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6132 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6374 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6615 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6401 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6286 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6494 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6512 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6316 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6513 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6759 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6669 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6603 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6300 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6576 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6573 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6419 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6351 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6480 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6106 - accuracy: 0.6667 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6398 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6365 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6709 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6466 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6369 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6621 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6266 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6451 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6455 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6328 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6268 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6433 - accuracy: 0.6667 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6325 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6269 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6422 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6442 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6426 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6293 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6158 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6414 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6567 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6462 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6521 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6463 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6471 - accuracy: 0.6667 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6438 - accuracy: 0.6667 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6521 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6142 - accuracy: 0.6667 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6530 - accuracy: 0.6667 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6363 - accuracy: 0.6667 - val_loss: 0.6395 - val_accuracy: 0.6667\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6366 - accuracy: 0.6667 - val_loss: 0.6398 - val_accuracy: 0.6667\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6626 - accuracy: 0.6667 - val_loss: 0.6403 - val_accuracy: 0.6667\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6538 - accuracy: 0.6667 - val_loss: 0.6409 - val_accuracy: 0.6667\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6412 - accuracy: 0.6667 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6470 - accuracy: 0.6667 - val_loss: 0.6407 - val_accuracy: 0.6667\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6403 - accuracy: 0.6667 - val_loss: 0.6402 - val_accuracy: 0.6667\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6313 - accuracy: 0.6667 - val_loss: 0.6401 - val_accuracy: 0.6667\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6511 - accuracy: 0.6667 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6527 - accuracy: 0.6667 - val_loss: 0.6398 - val_accuracy: 0.6667\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6553 - accuracy: 0.6667 - val_loss: 0.6397 - val_accuracy: 0.6667\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6211 - accuracy: 0.6667 - val_loss: 0.6398 - val_accuracy: 0.6667\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6228 - accuracy: 0.6667 - val_loss: 0.6396 - val_accuracy: 0.6667\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6226 - accuracy: 0.6667 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6269 - accuracy: 0.6667 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6539 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6175 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6389 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6357 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6437 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6340 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6385 - accuracy: 0.6667 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6387 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6361 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6324 - accuracy: 0.6667 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6439 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6354 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6418 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6493 - accuracy: 0.6667 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6296 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6496 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6453 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6358 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6443 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6445 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6448 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6680 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6553 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6453 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6473 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6419 - accuracy: 0.6667 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6422 - accuracy: 0.6667 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6339 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6089 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6173 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6441 - accuracy: 0.6667 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6595 - accuracy: 0.6667 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6552 - accuracy: 0.6667 - val_loss: 0.6395 - val_accuracy: 0.6667\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6325 - accuracy: 0.6667 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6609 - accuracy: 0.6667 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6413 - accuracy: 0.6667 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6537 - accuracy: 0.6667 - val_loss: 0.6404 - val_accuracy: 0.6667\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6394 - accuracy: 0.6667 - val_loss: 0.6402 - val_accuracy: 0.6667\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6376 - accuracy: 0.6667 - val_loss: 0.6393 - val_accuracy: 0.6667\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6192 - accuracy: 0.6667 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6501 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6563 - accuracy: 0.6667 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6272 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6399 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 384/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6515 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6370 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6420 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6522 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6458 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6530 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6292 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6581 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6352 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6375 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6344 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6304 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6649 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6668 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6368 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6379 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6367 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 401/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6435 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6483 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6347 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6630 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6390 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6375 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6574 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6529 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6219 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6469 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6277 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6176 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6347 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6649 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6391 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6450 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6273 - accuracy: 0.6667 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6333 - accuracy: 0.6667 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6499 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6320 - accuracy: 0.6667 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6349 - accuracy: 0.6667 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6388 - accuracy: 0.6667 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6230 - accuracy: 0.6667 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6520 - accuracy: 0.6667 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6427 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6406 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6286 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6596 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6388 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6350 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6406 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6367 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6562 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6292 - accuracy: 0.6667 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6405 - accuracy: 0.6667 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6382 - accuracy: 0.6667 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6456 - accuracy: 0.6667 - val_loss: 0.6395 - val_accuracy: 0.6667\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6479 - accuracy: 0.6667 - val_loss: 0.6404 - val_accuracy: 0.6667\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6320 - accuracy: 0.6667 - val_loss: 0.6411 - val_accuracy: 0.6667\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6359 - accuracy: 0.6667 - val_loss: 0.6412 - val_accuracy: 0.6667\n",
      "Epoch 441/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6298 - accuracy: 0.6667 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6505 - accuracy: 0.6667 - val_loss: 0.6408 - val_accuracy: 0.6667\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6485 - accuracy: 0.6667 - val_loss: 0.6404 - val_accuracy: 0.6667\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6468 - accuracy: 0.6667 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6448 - accuracy: 0.6667 - val_loss: 0.6395 - val_accuracy: 0.6667\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6377 - accuracy: 0.6667 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6493 - accuracy: 0.6667 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6396 - accuracy: 0.6667 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6480 - accuracy: 0.6667 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6380 - accuracy: 0.6667 - val_loss: 0.6392 - val_accuracy: 0.6667\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6418 - accuracy: 0.6667 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6471 - accuracy: 0.6667 - val_loss: 0.6389 - val_accuracy: 0.6667\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6529 - accuracy: 0.6667 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6494 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6333 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6533 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6426 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 458/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6404 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6239 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6434 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6208 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6367 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6600 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6504 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6364 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6223 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6357 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6477 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6384 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6620 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6526 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6338 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6409 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6391 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6369 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6565 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6446 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6615 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6336 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6497 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6344 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6388 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6651 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6286 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6449 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6304 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6405 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6614 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6356 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.6771 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6348 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6302 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6284 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.6295 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6547 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.6338 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.6588 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 498/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.6179 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.6355 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.6564 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 501/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.6659 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6291 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6490 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6621 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6494 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6495 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6444 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6507 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6469 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6144 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6488 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6245 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6329 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6268 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 515/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6546 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6377 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6334 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6411 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6511 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6298 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6403 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6307 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6591 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6436 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6511 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6302 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6361 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6274 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6588 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6250 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6479 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6642 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6327 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6214 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6486 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6377 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6452 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6457 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6410 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 540/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6319 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 541/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6459 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 542/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6437 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 543/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6208 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 544/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6511 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 545/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6330 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 546/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6497 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 547/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6360 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 548/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6520 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 549/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6489 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 550/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6538 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 551/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6220 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 552/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6245 - accuracy: 0.6667 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
      "Epoch 553/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6426 - accuracy: 0.6667 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
      "Epoch 554/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6357 - accuracy: 0.6667 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
      "Epoch 555/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6584 - accuracy: 0.6667 - val_loss: 0.6398 - val_accuracy: 0.6667\n",
      "Epoch 556/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6459 - accuracy: 0.6667 - val_loss: 0.6404 - val_accuracy: 0.6667\n",
      "Epoch 557/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6482 - accuracy: 0.6667 - val_loss: 0.6408 - val_accuracy: 0.6667\n",
      "Epoch 558/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6543 - accuracy: 0.6667 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
      "Epoch 559/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6519 - accuracy: 0.6667 - val_loss: 0.6409 - val_accuracy: 0.6667\n",
      "Epoch 560/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6467 - accuracy: 0.6667 - val_loss: 0.6408 - val_accuracy: 0.6667\n",
      "Epoch 561/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6405 - accuracy: 0.6667 - val_loss: 0.6408 - val_accuracy: 0.6667\n",
      "Epoch 562/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6321 - accuracy: 0.6667 - val_loss: 0.6404 - val_accuracy: 0.6667\n",
      "Epoch 563/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6420 - accuracy: 0.6667 - val_loss: 0.6398 - val_accuracy: 0.6667\n",
      "Epoch 564/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6412 - accuracy: 0.6667 - val_loss: 0.6392 - val_accuracy: 0.6667\n",
      "Epoch 565/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6375 - accuracy: 0.6667 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
      "Epoch 566/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6346 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 567/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6402 - accuracy: 0.6667 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
      "Epoch 568/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6609 - accuracy: 0.6667 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
      "Epoch 569/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6378 - accuracy: 0.6667 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
      "Epoch 570/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6533 - accuracy: 0.6667 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 571/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6192 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 572/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6288 - accuracy: 0.6667 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
      "Epoch 573/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6188 - accuracy: 0.6667 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
      "Epoch 574/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6375 - accuracy: 0.6667 - val_loss: 0.6393 - val_accuracy: 0.6667\n",
      "Epoch 575/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6340 - accuracy: 0.6667 - val_loss: 0.6397 - val_accuracy: 0.6667\n",
      "Epoch 576/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6533 - accuracy: 0.6667 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
      "Epoch 577/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6390 - accuracy: 0.6667 - val_loss: 0.6401 - val_accuracy: 0.6667\n",
      "Epoch 578/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6372 - accuracy: 0.6667 - val_loss: 0.6401 - val_accuracy: 0.6667\n",
      "Epoch 579/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6284 - accuracy: 0.6667 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
      "Epoch 580/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6395 - accuracy: 0.6667 - val_loss: 0.6396 - val_accuracy: 0.6667\n",
      "Epoch 581/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6383 - accuracy: 0.6667 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
      "Epoch 582/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6668 - accuracy: 0.6667 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 583/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6482 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 584/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6399 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 585/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6322 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 586/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6582 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 587/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6240 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 588/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6433 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 589/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6311 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 590/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6331 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 591/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6574 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 592/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6275 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 593/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6462 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 594/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6385 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 595/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6233 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 596/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6317 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 597/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6316 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 598/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6444 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 599/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6467 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 600/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6587 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 601/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6289 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 602/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6469 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 603/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6641 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 604/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6418 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 605/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6441 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 606/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6442 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 607/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6389 - accuracy: 0.6667 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
      "Epoch 608/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6355 - accuracy: 0.6667 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
      "Epoch 609/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6321 - accuracy: 0.6667 - val_loss: 0.6393 - val_accuracy: 0.6667\n",
      "Epoch 610/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6456 - accuracy: 0.6667 - val_loss: 0.6392 - val_accuracy: 0.6667\n",
      "Epoch 611/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6418 - accuracy: 0.6667 - val_loss: 0.6389 - val_accuracy: 0.6667\n",
      "Epoch 612/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6317 - accuracy: 0.6667 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 613/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6475 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 614/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6259 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 615/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6424 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 616/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6528 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 617/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6579 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 618/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6497 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 619/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6388 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 620/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6384 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 621/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6378 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 622/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6361 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 623/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6458 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 624/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6388 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 625/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6449 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 626/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6402 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 627/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6521 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 628/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6436 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 629/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6381 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 630/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6497 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 631/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6477 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 632/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6472 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 633/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6462 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 634/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6425 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 635/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6530 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 636/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6219 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 637/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6422 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 638/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6497 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 639/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6361 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 640/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6170 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 641/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6285 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 642/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6475 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 643/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6326 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 644/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6538 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 645/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6470 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 646/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6182 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 647/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6506 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 648/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6223 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 649/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6258 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 650/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6412 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 651/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6353 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 652/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6418 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 653/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6528 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 654/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6443 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 655/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6390 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 656/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6373 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 657/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6319 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 658/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6526 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 659/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6338 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 660/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6206 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 661/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6256 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 662/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6384 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 663/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6374 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 664/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6415 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 665/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6224 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 666/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6499 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 667/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6255 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 668/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6407 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 669/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6458 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 670/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6412 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 671/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6531 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 672/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6388 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 673/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6774 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 674/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6402 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 675/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6150 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 676/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6061 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 677/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6398 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 678/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6282 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 679/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6227 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 680/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6430 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 681/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6296 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 682/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6509 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 683/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6297 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 684/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6420 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 685/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6179 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 686/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6273 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 687/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6846 - accuracy: 0.6667 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
      "Epoch 688/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6088 - accuracy: 0.6667 - val_loss: 0.6398 - val_accuracy: 0.6667\n",
      "Epoch 689/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6244 - accuracy: 0.6667 - val_loss: 0.6407 - val_accuracy: 0.6667\n",
      "Epoch 690/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6332 - accuracy: 0.6667 - val_loss: 0.6412 - val_accuracy: 0.6667\n",
      "Epoch 691/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6291 - accuracy: 0.6667 - val_loss: 0.6414 - val_accuracy: 0.6667\n",
      "Epoch 692/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6433 - accuracy: 0.6667 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
      "Epoch 693/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6384 - accuracy: 0.6667 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
      "Epoch 694/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6444 - accuracy: 0.6667 - val_loss: 0.6407 - val_accuracy: 0.6667\n",
      "Epoch 695/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6446 - accuracy: 0.6667 - val_loss: 0.6404 - val_accuracy: 0.6667\n",
      "Epoch 696/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6405 - accuracy: 0.6667 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
      "Epoch 697/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6355 - accuracy: 0.6667 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
      "Epoch 698/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6453 - accuracy: 0.6667 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
      "Epoch 699/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6310 - accuracy: 0.6667 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
      "Epoch 700/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6505 - accuracy: 0.6667 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
      "Epoch 701/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6825 - accuracy: 0.6667 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
      "Epoch 702/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6358 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 703/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6459 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 704/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6487 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 705/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6172 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 706/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6412 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 707/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.6571 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 708/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6655 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 709/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6414 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 710/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6308 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 711/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6417 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 712/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6171 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 713/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6477 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 714/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6519 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 715/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6277 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 716/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6238 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 717/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6411 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 718/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6362 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 719/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6919 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 720/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6423 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 721/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6626 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 722/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6431 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 723/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6470 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 724/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6311 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 725/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6506 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 726/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6428 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 727/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6339 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 728/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6267 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 729/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6406 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 730/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6425 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 731/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6438 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 732/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6240 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 733/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6521 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 734/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6408 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 735/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6527 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 736/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6293 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 737/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6382 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 738/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6462 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 739/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6328 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 740/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6337 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 741/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6379 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 742/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6179 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 743/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6327 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 744/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6248 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 745/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6517 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 746/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6184 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 747/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6292 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 748/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6472 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 749/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6450 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 750/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6304 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 751/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6412 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 752/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6188 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 753/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6477 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 754/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6670 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 755/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6370 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 756/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6586 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 757/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6180 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 758/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6382 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 759/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6344 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 760/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6525 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 761/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6288 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 762/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6562 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 763/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6364 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 764/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6291 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 765/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6455 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 766/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6268 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 767/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6377 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 768/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6409 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 769/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6267 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 770/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6364 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 771/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6565 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 772/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6399 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 773/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6423 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 774/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6308 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 775/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6396 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 776/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6338 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 777/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6464 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 778/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6429 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 779/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6552 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 780/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6613 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 781/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6228 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 782/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6417 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 783/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6232 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 784/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6458 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 785/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6274 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 786/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6472 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 787/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6483 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 788/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6522 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 789/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6333 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 790/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6369 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 791/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6355 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 792/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6382 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 793/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6311 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 794/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6390 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 795/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6122 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 796/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6564 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 797/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6459 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 798/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6562 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 799/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6332 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 800/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6203 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 801/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6341 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 802/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6249 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 803/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6547 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 804/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6462 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 805/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6558 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 806/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6604 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 807/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6246 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 808/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6314 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 809/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6311 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 810/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6326 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 811/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6404 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 812/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6295 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 813/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6288 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 814/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6564 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 815/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6309 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 816/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6442 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 817/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6655 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 818/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6546 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 819/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6362 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 820/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.6448 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 821/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6491 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 822/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6543 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 823/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6439 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 824/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6226 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 825/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6449 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 826/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6508 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 827/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6426 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 828/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6501 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 829/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6302 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 830/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6341 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 831/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6371 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 832/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6441 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 833/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6172 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 834/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6383 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 835/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6459 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 836/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6289 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 837/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6558 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 838/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6213 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 839/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6135 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 840/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6431 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 841/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6310 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 842/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6293 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 843/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6275 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 844/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6346 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 845/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6494 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 846/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6412 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 847/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6382 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 848/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6334 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 849/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6447 - accuracy: 0.6667 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 850/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6211 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 851/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6445 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 852/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6435 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 853/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6502 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 854/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6525 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 855/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6335 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 856/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6572 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 857/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6423 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 858/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6404 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 859/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6338 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 860/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6491 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 861/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6339 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 862/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6363 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 863/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6425 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 864/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6551 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 865/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6471 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 866/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6324 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 867/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6241 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 868/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6286 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 869/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6240 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 870/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6512 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 871/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6349 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 872/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6476 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 873/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6381 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 874/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6430 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 875/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6363 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 876/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6394 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 877/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6350 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 878/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6373 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 879/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6464 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 880/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6328 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 881/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6316 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 882/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6432 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 883/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6400 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 884/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6359 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 885/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6238 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 886/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6505 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 887/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6294 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 888/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6257 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 889/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6542 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 890/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6242 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 891/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6464 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 892/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6292 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 893/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6433 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 894/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6260 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 895/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6256 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 896/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6384 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 897/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6333 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 898/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6637 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 899/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6573 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 900/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6512 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 901/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.6418 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 902/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6469 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 903/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6375 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 904/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6404 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 905/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6458 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 906/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6292 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 907/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6347 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 908/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6291 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 909/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6390 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 910/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6384 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 911/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6421 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 912/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6573 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 913/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6245 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 914/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6327 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 915/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6406 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 916/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6407 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 917/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6337 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 918/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6538 - accuracy: 0.6667 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
      "Epoch 919/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6371 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 920/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6494 - accuracy: 0.6667 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 921/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6498 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 922/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6401 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 923/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6328 - accuracy: 0.6667 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 924/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6471 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 925/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6162 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 926/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6443 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 927/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6349 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 928/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6325 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 929/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6291 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 930/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6463 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 931/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6337 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 932/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6389 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 933/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6394 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 934/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6224 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 935/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6489 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 936/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6210 - accuracy: 0.6667 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
      "Epoch 937/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6443 - accuracy: 0.6667 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
      "Epoch 938/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6343 - accuracy: 0.6667 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
      "Epoch 939/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6324 - accuracy: 0.6667 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
      "Epoch 940/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6117 - accuracy: 0.6667 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
      "Epoch 941/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6510 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 942/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6478 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6667\n",
      "Epoch 943/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6655 - accuracy: 0.6667 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 944/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6662 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 945/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6404 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 946/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6304 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 947/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6524 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 948/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6507 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 949/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6571 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 950/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6408 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 951/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6240 - accuracy: 0.6667 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
      "Epoch 952/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6598 - accuracy: 0.6667 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
      "Epoch 953/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6403 - accuracy: 0.6667 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
      "Epoch 954/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6123 - accuracy: 0.6667 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
      "Epoch 955/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6393 - accuracy: 0.6667 - val_loss: 0.6405 - val_accuracy: 0.6667\n",
      "Epoch 956/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6562 - accuracy: 0.6667 - val_loss: 0.6408 - val_accuracy: 0.6667\n",
      "Epoch 957/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6450 - accuracy: 0.6667 - val_loss: 0.6411 - val_accuracy: 0.6667\n",
      "Epoch 958/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6455 - accuracy: 0.6667 - val_loss: 0.6414 - val_accuracy: 0.6667\n",
      "Epoch 959/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6468 - accuracy: 0.6667 - val_loss: 0.6417 - val_accuracy: 0.6667\n",
      "Epoch 960/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6514 - accuracy: 0.6667 - val_loss: 0.6418 - val_accuracy: 0.6667\n",
      "Epoch 961/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6644 - accuracy: 0.6667 - val_loss: 0.6419 - val_accuracy: 0.6667\n",
      "Epoch 962/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6382 - accuracy: 0.6667 - val_loss: 0.6419 - val_accuracy: 0.6667\n",
      "Epoch 963/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6332 - accuracy: 0.6667 - val_loss: 0.6420 - val_accuracy: 0.6667\n",
      "Epoch 964/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6291 - accuracy: 0.6667 - val_loss: 0.6419 - val_accuracy: 0.6667\n",
      "Epoch 965/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6451 - accuracy: 0.6667 - val_loss: 0.6415 - val_accuracy: 0.6667\n",
      "Epoch 966/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6465 - accuracy: 0.6667 - val_loss: 0.6411 - val_accuracy: 0.6667\n",
      "Epoch 967/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6434 - accuracy: 0.6667 - val_loss: 0.6408 - val_accuracy: 0.6667\n",
      "Epoch 968/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6432 - accuracy: 0.6667 - val_loss: 0.6404 - val_accuracy: 0.6667\n",
      "Epoch 969/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6518 - accuracy: 0.6667 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
      "Epoch 970/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6360 - accuracy: 0.6667 - val_loss: 0.6395 - val_accuracy: 0.6667\n",
      "Epoch 971/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6465 - accuracy: 0.6667 - val_loss: 0.6392 - val_accuracy: 0.6667\n",
      "Epoch 972/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6316 - accuracy: 0.6667 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
      "Epoch 973/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6421 - accuracy: 0.6667 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
      "Epoch 974/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6267 - accuracy: 0.6667 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
      "Epoch 975/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6277 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 976/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6277 - accuracy: 0.6667 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 977/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6471 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 978/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6656 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
      "Epoch 979/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6271 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 980/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6444 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 981/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6474 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 982/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6366 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 983/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6117 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 984/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6441 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 985/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6236 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 986/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6576 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 987/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6501 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 988/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6236 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 989/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6435 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 990/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6289 - accuracy: 0.6667 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
      "Epoch 991/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6529 - accuracy: 0.6667 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
      "Epoch 992/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6364 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 993/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6471 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 994/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6224 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 995/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6287 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 996/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6116 - accuracy: 0.6667 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 997/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6433 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 998/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6451 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 999/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6370 - accuracy: 0.6667 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 1000/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6370 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6381 - accuracy: 0.6667\n",
      "Test Loss: 0.6380974054336548\n",
      "Test Accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "# Hun luyn m hnh\n",
    "history = model.fit(xTrain, yTrain, batch_size=32, epochs=1000, validation_data=(xTest, yTest))\n",
    "\n",
    "# nh gi m hnh trn d liu kim tra\n",
    "loss, accuracy = model.evaluate(xTest, yTest)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGzCAYAAAAMr0ziAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAACcw0lEQVR4nO2deXgVRdb/vzeBJCAkgRCSkIRVRARchm0AAR2ZwWVERBQVBdTBUdniwg8YUIiKzKsiIC6M846gIqsEV1wIhndUEHHBwY1lZJMRFJUEBAK5qd8fPX3T96aXqu7q5d6cz/P0A7m3b3d1ddWpU6fOORVijDEQBEEQBEEEmCS/C0AQBEEQBGEFKSwEQRAEQQQeUlgIgiAIggg8pLAQBEEQBBF4SGEhCIIgCCLwkMJCEARBEETgIYWFIAiCIIjAQwoLQRAEQRCBhxQWgiAIgiACDyksBCGJUaNGoXXr1rZ+O2PGDIRCIbkFChi7d+9GKBTCokWLPL3v+vXrEQqFsH79+shnvO/KrTK3bt0ao0aNknpNHhYtWoRQKITdu3d7fm+CcAopLETCEwqFuA7tgEYQTtmwYQNmzJiBw4cP+10UgkgI6vldAIJwmxdeeCHq7+effx5r166t9XnHjh0d3efvf/87qqurbf122rRpmDx5sqP7E/w4eVe8bNiwAcXFxRg1ahQyMzOjvtu2bRuSkmi+SBAikMJCJDw33HBD1N8ffvgh1q5dW+vzWI4dO4aGDRty36d+/fq2ygcA9erVQ7161B29wsm7kkFqaqqv9yeIeIRUfIIAcMEFF6Bz58745JNP0K9fPzRs2BB/+ctfAACvvPIKLrvsMrRo0QKpqalo164dHnjgAYTD4ahrxPpFqP4Pjz76KJ555hm0a9cOqamp6N69OzZv3hz1Wz0fllAohLFjx+Lll19G586dkZqaik6dOuGtt96qVf7169ejW7duSEtLQ7t27fC3v/2N2y/mvffew9VXX42WLVsiNTUVhYWFuPPOO3H8+PFaz9eoUSPs378fgwcPRqNGjZCdnY177rmnVl0cPnwYo0aNQkZGBjIzMzFy5EiupZGPP/4YoVAIzz33XK3v3n77bYRCIbz++usAgD179uCOO+5Ahw4d0KBBA2RlZeHqq6/m8s/Q82HhLfO//vUvjBo1Cm3btkVaWhpyc3Nx880346effoqcM2PGDEycOBEA0KZNm8iyo1o2PR+Wb7/9FldffTWaNm2Khg0b4re//S3eeOONqHNUf5wVK1Zg5syZKCgoQFpaGi666CLs3LnT8rmNeOqpp9CpUyekpqaiRYsWGDNmTK1n37FjB6666irk5uYiLS0NBQUFuPbaa1FeXh45Z+3atTj//PORmZmJRo0aoUOHDpF+RBBOoSkdQfyXn376CZdccgmuvfZa3HDDDcjJyQGgOCo2atQId911Fxo1aoR3330X9913HyoqKvDII49YXnfJkiU4cuQI/vznPyMUCuHhhx/GkCFD8O2331rO9N9//32UlJTgjjvuQOPGjfH444/jqquuwt69e5GVlQUA+Oyzz3DxxRcjLy8PxcXFCIfDuP/++5Gdnc313CtXrsSxY8dw++23IysrCx999BHmz5+P7777DitXrow6NxwOY+DAgejZsyceffRRlJaWYvbs2WjXrh1uv/12AABjDFdccQXef/993HbbbejYsSNWr16NkSNHWpalW7duaNu2LVasWFHr/OXLl6NJkyYYOHAgAGDz5s3YsGEDrr32WhQUFGD37t14+umnccEFF+Crr74Sso6JlHnt2rX49ttvcdNNNyE3NxdffvklnnnmGXz55Zf48MMPEQqFMGTIEGzfvh1Lly7FnDlz0KxZMwAwfCcHDx5E7969cezYMYwfPx5ZWVl47rnnMGjQILz00ku48soro87/61//iqSkJNxzzz0oLy/Hww8/jOHDh2PTpk3cz6wyY8YMFBcXY8CAAbj99tuxbds2PP3009i8eTM++OAD1K9fHydPnsTAgQNRWVmJcePGITc3F/v378frr7+Ow4cPIyMjA19++SX++Mc/4uyzz8b999+P1NRU7Ny5Ex988IFwmQhCF0YQdYwxY8aw2Kbfv39/BoAtWLCg1vnHjh2r9dmf//xn1rBhQ3bixInIZyNHjmStWrWK/L1r1y4GgGVlZbGff/458vkrr7zCALDXXnst8tn06dNrlQkAS0lJYTt37ox89vnnnzMAbP78+ZHPLr/8ctawYUO2f//+yGc7duxg9erVq3VNPfSeb9asWSwUCrE9e/ZEPR8Adv/990ede95557GuXbtG/n755ZcZAPbwww9HPquqqmJ9+/ZlANjChQtNyzNlyhRWv379qDqrrKxkmZmZ7OabbzYt98aNGxkA9vzzz0c+KysrYwBYWVlZ1LNo35VImfXuu3TpUgaA/fOf/4x89sgjjzAAbNeuXbXOb9WqFRs5cmTk76KiIgaAvffee5HPjhw5wtq0acNat27NwuFw1LN07NiRVVZWRs6dN28eA8C2bt1a615aFi5cGFWmH374gaWkpLA//OEPkXswxtgTTzzBALBnn32WMcbYZ599xgCwlStXGl57zpw5DAD78ccfTctAEHahJSGC+C+pqam46aaban3eoEGDyP+PHDmCQ4cOoW/fvjh27Bi++eYby+sOGzYMTZo0ifzdt29fAMoSgBUDBgxAu3btIn+fffbZSE9Pj/w2HA6jtLQUgwcPRosWLSLnnX766bjkkkssrw9EP9+vv/6KQ4cOoXfv3mCM4bPPPqt1/m233Rb1d9++faOeZc2aNahXr17E4gIAycnJGDduHFd5hg0bhlOnTqGkpCTy2TvvvIPDhw9j2LBhuuU+deoUfvrpJ5x++unIzMzEp59+ynUvO2XW3vfEiRM4dOgQfvvb3wKA8H219+/RowfOP//8yGeNGjXCrbfeit27d+Orr76KOv+mm25CSkpK5G+RNqWltLQUJ0+eRFFRUZQT8OjRo5Genh5ZksrIyACgLMsdO3ZM91qqY/Err7ziukMzUTchhYUg/kt+fn7UIKDy5Zdf4sorr0RGRgbS09ORnZ0dcdjVrt8b0bJly6i/VeXll19+Ef6t+nv1tz/88AOOHz+O008/vdZ5ep/psXfvXowaNQpNmzaN+KX0798fQO3nS0tLq7WsoS0PoPiW5OXloVGjRlHndejQgas855xzDs4880wsX7488tny5cvRrFkz/O53v4t8dvz4cdx3330oLCxEamoqmjVrhuzsbBw+fJjrvWgRKfPPP/+MCRMmICcnBw0aNEB2djbatGkDgK89GN1f715q5NqePXuiPnfSpmLvC9R+zpSUFLRt2zbyfZs2bXDXXXfhf//3f9GsWTMMHDgQTz75ZNTzDhs2DH369MGf/vQn5OTk4Nprr8WKFStIeSGkQT4sBPFftDNnlcOHD6N///5IT0/H/fffj3bt2iEtLQ2ffvopJk2axCWMk5OTdT9njLn6Wx7C4TB+//vf4+eff8akSZNw5pln4rTTTsP+/fsxatSoWs9nVB7ZDBs2DDNnzsShQ4fQuHFjvPrqq7juuuuiIqnGjRuHhQsXoqioCL169UJGRgZCoRCuvfZaVwfJa665Bhs2bMDEiRNx7rnnolGjRqiursbFF1/s2eDsdrvQY/bs2Rg1ahReeeUVvPPOOxg/fjxmzZqFDz/8EAUFBWjQoAH++c9/oqysDG+88QbeeustLF++HL/73e/wzjvveNZ2iMSFFBaCMGH9+vX46aefUFJSgn79+kU+37Vrl4+lqqF58+ZIS0vTjRDhiRrZunUrtm/fjueeew4jRoyIfL527VrbZWrVqhXWrVuHo0ePRlkstm3bxn2NYcOGobi4GKtWrUJOTg4qKipw7bXXRp3z0ksvYeTIkZg9e3bksxMnTthK1MZb5l9++QXr1q1DcXEx7rvvvsjnO3bsqHVNkczFrVq10q0fdcmxVatW3NcSQb3utm3b0LZt28jnJ0+exK5duzBgwICo87t06YIuXbpg2rRp2LBhA/r06YMFCxbgwQcfBAAkJSXhoosuwkUXXYTHHnsMDz30EKZOnYqysrJa1yIIUWhJiCBMUGeF2pnryZMn8dRTT/lVpCiSk5MxYMAAvPzyy/jPf/4T+Xznzp148803uX4PRD8fYwzz5s2zXaZLL70UVVVVePrppyOfhcNhzJ8/n/saHTt2RJcuXbB8+XIsX74ceXl5UQqjWvZYi8L8+fNrhVjLLLNefQHA3Llza13ztNNOAwAuBerSSy/FRx99hI0bN0Y++/XXX/HMM8+gdevWOOuss3gfRYgBAwYgJSUFjz/+eNQz/eMf/0B5eTkuu+wyAEBFRQWqqqqiftulSxckJSWhsrISgLJUFsu5554LAJFzCMIJZGEhCBN69+6NJk2aYOTIkRg/fjxCoRBeeOEFV03vosyYMQPvvPMO+vTpg9tvvx3hcBhPPPEEOnfujC1btpj+9swzz0S7du1wzz33YP/+/UhPT8eqVauEfSG0XH755ejTpw8mT56M3bt346yzzkJJSYmwf8ewYcNw3333IS0tDbfcckutzLB//OMf8cILLyAjIwNnnXUWNm7ciNLS0ki4txtlTk9PR79+/fDwww/j1KlTyM/PxzvvvKNrcevatSsAYOrUqbj22mtRv359XH755RFFRsvkyZOxdOlSXHLJJRg/fjyaNm2K5557Drt27cKqVatcy4qbnZ2NKVOmoLi4GBdffDEGDRqEbdu24amnnkL37t0jvlrvvvsuxo4di6uvvhpnnHEGqqqq8MILLyA5ORlXXXUVAOD+++/HP//5T1x22WVo1aoVfvjhBzz11FMoKCiIciYmCLuQwkIQJmRlZeH111/H3XffjWnTpqFJkya44YYbcNFFF0XygfhN165d8eabb+Kee+7Bvffei8LCQtx///34+uuvLaOY6tevj9deey3ij5CWloYrr7wSY8eOxTnnnGOrPElJSXj11VdRVFSExYsXIxQKYdCgQZg9ezbOO+887usMGzYM06ZNw7Fjx6Kig1TmzZuH5ORkvPjiizhx4gT69OmD0tJSW+9FpMxLlizBuHHj8OSTT4Ixhj/84Q948803o6K0AKB79+544IEHsGDBArz11luorq7Grl27dBWWnJwcbNiwAZMmTcL8+fNx4sQJnH322XjttdciVg63mDFjBrKzs/HEE0/gzjvvRNOmTXHrrbfioYceiuQJOuecczBw4EC89tpr2L9/Pxo2bIhzzjkHb775ZiRCatCgQdi9ezeeffZZHDp0CM2aNUP//v1RXFwciTIiCCeEWJCmigRBSGPw4MH48ssvdf0rCIIg4g3yYSGIBCA2jf6OHTuwZs0aXHDBBf4UiCAIQjJkYSGIBCAvLy+yv82ePXvw9NNPo7KyEp999hnat2/vd/EIgiAcQz4sBJEAXHzxxVi6dCkOHDiA1NRU9OrVCw899BApKwRBJAxkYSEIgiAIIvCQDwtBEARBEIGHFBaCIAiCIAJPwviwVFdX4z//+Q8aN24slBKbIAiCIAj/YIzhyJEjaNGihWmSxIRRWP7zn/+gsLDQ72IQBEEQBGGDffv2oaCgwPD7hFFYGjduDEB54PT0dJ9LQxAEQRAEDxUVFSgsLIyM40YkjMKiLgOlp6eTwkIQBEEQcYaVOwc53RIEQRAEEXhIYSEIgiAIIvCQwkIQBEEQROBJGB8WgohXwuEwTp065XcxiAQgOTkZ9erVo9QOREJCCgtB+MjRo0fx3XffgXbIIGTRsGFD5OXlISUlxe+iEIRUSGEhCJ8Ih8P47rvv0LBhQ2RnZ9OsmHAEYwwnT57Ejz/+iF27dqF9+/amSbgIIt4ghYUgfOLUqVNgjCE7OxsNGjTwuzhEAtCgQQPUr18fe/bswcmTJ5GWluZ3kQhCGqR+E4TPkGWFkAlZVYhEhSwshGuEw8B77wHffw/k5QF9+wLJyX6XiiAIgohHSGEhXKGkBJgwAfjuu5rPCgqAefOAIUP8KxdBEAQRn5DtkJBOSQkwdGi0sgIA+/crn5eU+FOuRCUcBtavB5YuVf4Nh/0ukTitW7fG3Llzuc9fv349QqEQDh8+7FqZAGDRokXIzMx09R4EQfBBCgshlXBYsazoRemqnxUVxeegGkRKSoDWrYELLwSuv175t3Vr95TCUChkesyYMcPWdTdv3oxbb72V+/zevXvj+++/R0ZGhq37EQQRf9hSWJ588km0bt0aaWlp6NmzJz766CPDcy+44AJdwXbZZZdFzmGM4b777kNeXh4aNGiAAQMGYMeOHXaKRvjMe+/VtqxoYQzYt085j3CGH5as77//PnLMnTsX6enpUZ/dc889kXMZY6iqquK6bnZ2Nho2bMhdjpSUFOTm5pLDMkHUIYQVluXLl+Ouu+7C9OnT8emnn+Kcc87BwIED8cMPP+ieX1JSEiXQvvjiCyQnJ+Pqq6+OnPPwww/j8ccfx4IFC7Bp0yacdtppGDhwIE6cOGH/yQhf+P57uecR+vhlycrNzY0cGRkZCIVCkb+/+eYbNG7cGG+++Sa6du2K1NRUvP/++/j3v/+NK664Ajk5OWjUqBG6d++O0tLSqOvGLgmFQiH87//+L6688ko0bNgQ7du3x6uvvhr5PnZJSF26efvtt9GxY0c0atQIF198Mb7XNLSqqiqMHz8emZmZyMrKwqRJkzBy5EgMHjxYqA6efvpptGvXDikpKejQoQNeeOGFyHeMMcyYMQMtW7ZEamoqWrRogfHjx0e+f+qpp9C+fXukpaUhJycHQ4cOFbo3QdRpmCA9evRgY8aMifwdDodZixYt2KxZs7h+P2fOHNa4cWN29OhRxhhj1dXVLDc3lz3yyCORcw4fPsxSU1PZ0qVLuctVXl7OALDy8nLu3xDyKStjTBkyzY+yMr9L6j/Hjx9nX331FTt+/Ljwb4NQzwsXLmQZGRmaMpUxAOzss89m77zzDtu5cyf76aef2JYtW9iCBQvY1q1b2fbt29m0adNYWloa27NnT+S3rVq1YnPmzIn8DYAVFBSwJUuWsB07drDx48ezRo0asZ9++inqXr/88kukLPXr12cDBgxgmzdvZp988gnr2LEju/766yPXfPDBB1nTpk1ZSUkJ+/rrr9ltt93G0tPT2RVXXMH9jCUlJax+/frsySefZNu2bWOzZ89mycnJ7N1332WMMbZy5UqWnp7O1qxZw/bs2cM2bdrEnnnmGcYYY5s3b2bJyclsyZIlbPfu3ezTTz9l8+bNs1n7xjhpVwThB7zjt5DCUllZyZKTk9nq1aujPh8xYgQbNGgQ1zU6d+7MRo8eHfn73//+NwPAPvvss6jz+vXrx8aPH294nRMnTrDy8vLIsW/fPlJYAkBVFWMFBYyFQvoDaCjEWGGhcl5dx8nAsmQJn8KyZIkLBf8vRgrLyy+/bPnbTp06sfnz50f+1lNYpk2bFvn76NGjDAB78803o+6lVVgAsJ07d0Z+8+STT7KcnJzI3zk5OVETo6qqKtayZUshhaV3795R8osxxq6++mp26aWXMsYYmz17NjvjjDPYyZMna11r1apVLD09nVVUVBjeTwaksBDxBq/CIrQkdOjQIYTDYeTk5ER9npOTgwMHDlj+/qOPPsIXX3yBP/3pT5HP1N+JXnPWrFnIyMiIHIWFhSKPQrhEcrISugwAse4F6t9z51I+Fqfk5ck9TybdunWL+vvo0aO455570LFjR2RmZqJRo0b4+uuvsXfvXtPrnH322ZH/n3baaUhPTzdcegaUPXTatWsX+TsvLy9yfnl5OQ4ePIgePXpEvk9OTkbXrl2Fnu3rr79Gnz59oj7r06cPvv76awDA1VdfjePHj6Nt27YYPXo0Vq9eHfHj+f3vf49WrVqhbdu2uPHGG/Hiiy/i2LFjQvcniLqMp1FC//jHP9ClS5cooWGXKVOmoLy8PHLs27dPQgkJGQwZArz0EpCfH/15QYHyOeVhcU7fvkp9GvmchkJAYaFyntecdtppUX/fc889WL16NR566CG899572LJlC7p06YKTJ0+aXqd+/fpRf4dCIVRXVwudzzzeVLKwsBDbtm3DU089hQYNGuCOO+5Av379cOrUKTRu3Biffvopli5diry8PNx3330455xzXA/NJohEQUhhadasGZKTk3Hw4MGozw8ePIjc3FzT3/76669YtmwZbrnllqjP1d+JXjM1NRXp6elRBxEchgwBdu8GysqAJUuUf3ftImVFFvFkyfrggw8watQoXHnllejSpQtyc3Oxe/duT8uQkZGBnJwcbN68OfJZOBzGp59+KnSdjh074oMPPoj67IMPPsBZZ50V+btBgwa4/PLL8fjjj2P9+vXYuHEjtm7dCgCoV68eBgwYgIcffhj/+te/sHv3brz77rsOnowg6g5CmW5TUlLQtWtXrFu3LuJZX11djXXr1mHs2LGmv125ciUqKytxww03RH3epk0b5ObmYt26dTj33HMBABUVFdi0aRNuv/12keIRASM5GbjgAr9Lkbioliy9jMJz5wZHOWzfvj1KSkpw+eWXIxQK4d577zW1lLjFuHHjMGvWLJx++uk488wzMX/+fPzyyy9CodETJ07ENddcg/POOw8DBgzAa6+9hpKSkkjU06JFixAOh9GzZ080bNgQixcvRoMGDdCqVSu8/vrr+Pbbb9GvXz80adIEa9asQXV1NTp06ODWIxNEQiGcmv+uu+7CyJEj0a1bN/To0QNz587Fr7/+iptuugkAMGLECOTn52PWrFlRv/vHP/6BwYMHIysrK+rzUCiEoqIiPPjgg2jfvj3atGmDe++9Fy1atBAONySIusaQIcAVVwR7z6bHHnsMN998M3r37o1mzZph0qRJqKio8LwckyZNwoEDBzBixAgkJyfj1ltvxcCBA5EsUFmDBw/GvHnz8Oijj2LChAlo06YNFi5ciAv+q5lnZmbir3/9K+666y6Ew2F06dIFr732GrKyspCZmYmSkhLMmDEDJ06cQPv27bF06VJ06tTJpScmiATDjkfv/PnzWcuWLVlKSgrr0aMH+/DDDyPf9e/fn40cOTLq/G+++YYBYO+8847u9aqrq9m9997LcnJyWGpqKrvooovYtm3bhMpEYc1EvEHRHP4SDofZGWecERWNlAhQuyLiDd7xO8SYx15pLlFRUYGMjAyUl5eTPwsRF5w4cQK7du1CmzZtkJaW5ndxEp49e/bgnXfeQf/+/VFZWYknnngCCxcuxOeff46OHTv6XTxpULsi4g3e8Zv2EiIIok6QlJSERYsWoXv37ujTpw+2bt2K0tLShFJWCCKREfZhIQiCiEcKCwtrRfgQBBE/kIWFIAiCIIjAQwoLQRAEQRCBhxQWgiAIgiACDyksBEEQBEEEHlJYCIIgCIIIPKSwEARBEAQReEhhIQjCcy644AIUFRVF/m7dujXmzp1r+ptQKISXX37Z8b1lXceMGTNmRPZGIwhCDqSwSCQcBtavB5YuVf4Nh/0uEUHI5fLLL8fFF1+s+917772HUCiEf/3rX8LX3bx5M2699VanxYvCSGn4/vvvcckll0i9F0EQ7kMKiyRKSoDWrYELLwSuv175t3Vr5XOCSBRuueUWrF27Ft9pt4f+LwsXLkS3bt1w9tlnC183OzsbDRs2lFFES3Jzc5GamurJvQiCkAcpLBIoKQGGDgViZfj+/crnpLQQPDAG/PqrPwfvjmJ//OMfkZ2djUWLFkV9fvToUaxcuRK33HILfvrpJ1x33XXIz89Hw4YN0aVLFyxdutT0urFLQjt27EC/fv2QlpaGs846C2vXrq31m0mTJuGMM85Aw4YN0bZtW9x77704deoUAGDRokUoLi7G559/jlAohFAoFClz7JLQ1q1b8bvf/Q4NGjRAVlYWbr31Vhw9ejTy/ahRozB48GA8+uijyMvLQ1ZWFsaMGRO5Fw/V1dW4//77UVBQgNTUVJx77rl46623It+fPHkSY8eORV5eHtLS0tCqVavIjveMMcyYMQMtW7ZEamoqWrRogfHjx3PfmyASBUrN75BwGJgwQV/gMwaEQkBREXDFFYB2F/twGHjvPeD774G8PKBv3+jvibrHsWNAo0b+3PvoUeC006zPq1evHkaMGIFFixZh6tSpCIVCAICVK1ciHA7juuuuw9GjR9G1a1dMmjQJ6enpeOONN3DjjTeiXbt26NGjh+U9qqurMWTIEOTk5GDTpk0oLy+P8ndRady4MRYtWoQWLVpg69atGD16NBo3boz/9//+H4YNG4YvvvgCb731FkpLSwEAGRkZta7x66+/YuDAgejVqxc2b96MH374AX/6058wduzYKKWsrKwMeXl5KCsrw86dOzFs2DCce+65GD16tHWlAZg3bx5mz56Nv/3tbzjvvPPw7LPPYtCgQfjyyy/Rvn17PP7443j11VexYsUKtGzZEvv27cO+ffsAAKtWrcKcOXOwbNkydOrUCQcOHMDnn3/OdV+CSCi82DraC3i3p5ZNWRljimpifpSV1fxm1SrGCgqivy8oUD4n6g7Hjx9nX331FTt+/DhjjLGjR/nakhvH0aP85f76668ZAFamadR9+/ZlN9xwg+FvLrvsMnb33XdH/u7fvz+bMGFC5O9WrVqxOXPmMMYYe/vtt1m9evXY/v37I9+/+eabDABbvXq14T0eeeQR1rVr18jf06dPZ+ecc06t87TXeeaZZ1iTJk3YUU0FvPHGGywpKYkdOHCAMcbYyJEjWatWrVhVVVXknKuvvpoNGzbMsCyx927RogWbOXNm1Dndu3dnd9xxB2OMsXHjxrHf/e53rLq6uta1Zs+ezc444wx28uRJw/tpiW1XBBF0eMdvWhJyyPffi51Hy0eEEQ0bKpYOPw4R95EzzzwTvXv3xrPPPgsA2LlzJ9577z3ccsstAIBwOIwHHngAXbp0QdOmTdGoUSO8/fbb2Lt3L9f1v/76axQWFqJFixaRz3r16lXrvOXLl6NPnz7Izc1Fo0aNMG3aNO57aO91zjnn4DSNealPnz6orq7Gtm3bIp916tQJyRoTaF5eHn744Qeue1RUVOA///kP+vTpE/V5nz598PXXXwNQlp22bNmCDh06YPz48XjnnXci51199dU4fvw42rZti9GjR2P16tWoqqoSek6CSARIYXFIXh7/eVbLR4CyfETRRXWTUEhZlvHj+O/KDje33HILVq1ahSNHjmDhwoVo164d+vfvDwB45JFHMG/ePEyaNAllZWXYsmULBg4ciJMnT0qrq40bN2L48OG49NJL8frrr+Ozzz7D1KlTpd5DS/369aP+DoVCqK6ulnb93/zmN9i1axceeOABHD9+HNdccw2GDh0KQNlletu2bXjqqafQoEED3HHHHejXr5+QDw1BJAKksDikb1+goMBY4IdCQGGhct5779W2rGhhDNi3TzmPIILMNddcg6SkJCxZsgTPP/88br755og/ywcffIArrrgCN9xwA8455xy0bdsW27dv5752x44dsW/fPnyvMV9++OGHUeds2LABrVq1wtSpU9GtWze0b98ee/bsiTonJSUFYQvtv2PHjvj888/x66+/Rj774IMPkJSUhA4dOnCX2Yz09HS0aNECH3zwQdTnH3zwAc4666yo84YNG4a///3vWL58OVatWoWff/4ZANCgQQNcfvnlePzxx7F+/Xps3LgRW7dulVI+XihtA+E35HTrkORkYN48ZTknFIq2nqhKzNy5ynmiy0cEEVQaNWqEYcOGYcqUKaioqMCoUaMi37Vv3x4vvfQSNmzYgCZNmuCxxx7DwYMHowZnMwYMGIAzzjgDI0eOxCOPPIKKigpMnTo16pz27dtj7969WLZsGbp374433ngDq1evjjqndevW2LVrF7Zs2YKCggI0bty4Vjjz8OHDMX36dIwcORIzZszAjz/+iHHjxuHGG29ETk6OvcrRYeLEiZg+fTratWuHc889FwsXLsSWLVvw4osvAgAee+wx5OXl4bzzzkNSUhJWrlyJ3NxcZGZmYtGiRQiHw+jZsycaNmyIxYsXo0GDBmjVqpW08llRUqJYh7UTroICRfYNGeJZMYg6DllYJDBkCPDSS0B+fvTnBQXK52qHFlk+Ioigc8stt+CXX37BwIEDo/xNpk2bht/85jcYOHAgLrjgAuTm5mLw4MHc101KSsLq1atx/Phx9OjRA3/6058wc+bMqHMGDRqEO++8E2PHjsW5556LDRs24N57740656qrrsLFF1+MCy+8ENnZ2bqh1Q0bNsTbb7+Nn3/+Gd27d8fQoUNx0UUX4YknnhCrDAvGjx+Pu+66C3fffTe6dOmCt956C6+++irat28PQIl4evjhh9GtWzd0794du3fvxpo1a5CUlITMzEz8/e9/R58+fXD22WejtLQUr732GrKysqSW0QjyuyOCQogx3gwMwaaiogIZGRkoLy9Henq6L2WwClUOh5Vkcvv36/uxhEKKkrNrF4U41wVOnDiBXbt2oU2bNkhLS/O7OESCILNdqTLLaCmbZBYhA97xm5aEJJKcDFxwgfn3vMtHBEEQfiPid2cm+whCBrQk5DG8y0cEQRB+Q353RJAgC4sPDBmiZL6lTLcEQQQZ8rsjggQpLD5htXxEEAThN2raBiu/u759vS8bUfegJaEAQXkO6iYJ4vdOBASZ7Un1uwNq55oivzvCa0hhCQglJYo3/oUXAtdfr/zbujWFDCYyaqp3t7KzEnWTY8eOAaidndcu5HdHBAUKaw4Aap6D2DehzmBIKCQmjDHs3bsXp06dQosWLZCURPMHwj6MMRw7dgw//PADMjMzkSfZsYR2mCfcgnf8JoXFZyjPQd3m5MmT2LVrl9R9aYi6TWZmJnJzcyNbJRBE0KE8LHEC5Tmo26SkpKB9+/a0LERIoX79+lG7ShNEIkEKi89QngMiKSmJMt0SBEFYQIvmPkN5DgiCIAjCGlJYfEbNc2C03BwKAYWFlOeAIAiCqNuQwuIzlOeAIAiCIKwhhSUAUJ4DgiAIgjCHnG4DAu0vRBAEQRDGkMISIGh/IYIgCILQh5aECIIgCIIIPKSwEARBEAQReEhhIQiCIAgi8JDCQhAEQRBE4CGnW4IgiDoE7bpMxCuksBAEQdQRSkqACROiN1wtKFCSV1K+JyLo0JIQQRBEHaCkBBg6tPbu8Pv3K5+XlPhTLoLghRQWgiCIBCccViwrjNX+Tv2sqEg5jyCCCiksBEEQCc5779W2rGhhDNi3TzmPIIIKKSwEQRAJzvffyz2PIPyAFBaCIIgEJy9P7nkE4QeksBAEQSQ4ffsq0UChkP73oRBQWKicRxBBhRQWgiCIBCc5WQldBmorLerfs2crPixLlwLr15MDLhE8KA8LQRBEHWDIEOCll/TzsFx7LXDXXZSfhQg2Icb0At3ij4qKCmRkZKC8vBzp6el+F4cgCCKQxGa6PXQIuOaa2iHPquXlpZdIaSHchXf8JgsLQRBEHSI5GbjgAuX/4TDQurVxfpZQSMnPcsUVlL6f8B/yYSEIgqijUH4WIp4ghYUgCKKOQvlZiHiCFBaCIIg6CuVnIeIJ8mGpY9DW8gRBqKj5Wfbv1/djCYWU7yk/CxEEyMJShygpURzsLrwQuP565d/WrWmXVoKoq/DkZ5k7lyY1RDCwpbA8+eSTaN26NdLS0tCzZ0989NFHpucfPnwYY8aMQV5eHlJTU3HGGWdgzZo1ke/D4TDuvfdetGnTBg0aNEC7du3wwAMPIEEirgMBbS1PEIQean6W/PzozwsKKKSZCBbCS0LLly/HXXfdhQULFqBnz56YO3cuBg4ciG3btqF58+a1zj958iR+//vfo3nz5njppZeQn5+PPXv2IDMzM3LO//zP/+Dpp5/Gc889h06dOuHjjz/GTTfdhIyMDIwfP97RAxLWW8tT6CJB1G2GDFH6Py0XE0FGOHFcz5490b17dzzxxBMAgOrqahQWFmLcuHGYPHlyrfMXLFiARx55BN988w3q16+ve80//vGPyMnJwT/+8Y/IZ1dddRUaNGiAxYsXc5WLEscZs369svxjRVlZTX4GgiAIgvAC3vFbaEno5MmT+OSTTzBgwICaCyQlYcCAAdi4caPub1599VX06tULY8aMQU5ODjp37oyHHnoIYc1GFb1798a6deuwfft2AMDnn3+O999/H5dccolhWSorK1FRURF1EPpQ6CJBEAQR7wgtCR06dAjhcBg5OTlRn+fk5OCbb77R/c23336Ld999F8OHD8eaNWuwc+dO3HHHHTh16hSmT58OAJg8eTIqKipw5plnIjk5GeFwGDNnzsTw4cMNyzJr1iwUFxeLFL/OQqGLBEEQRLzjepRQdXU1mjdvjmeeeQZdu3bFsGHDMHXqVCxYsCByzooVK/Diiy9iyZIl+PTTT/Hcc8/h0UcfxXPPPWd43SlTpqC8vDxy7Nu3z+1HiVtoa3mCIAgi3hGysDRr1gzJyck4ePBg1OcHDx5Ebm6u7m/y8vJQv359JGu8tzp27IgDBw7g5MmTSElJwcSJEzF58mRce+21AIAuXbpgz549mDVrFkaOHKl73dTUVKSmpooUv86ihi4OHaooJ1qvJQpdJAiCIOIBIQtLSkoKunbtinXr1kU+q66uxrp169CrVy/d3/Tp0wc7d+5EdXV15LPt27cjLy8PKSkpAIBjx44hKSm6KMnJyVG/IZwRxNDFcFhxCF66VPlX49ZEEARBEFEIhzXfddddGDlyJLp164YePXpg7ty5+PXXX3HTTTcBAEaMGIH8/HzMmjULAHD77bfjiSeewIQJEzBu3Djs2LEDDz30UFS48uWXX46ZM2eiZcuW6NSpEz777DM89thjuPnmmyU9JgEEK3SxpEQJtdbmhSkoUCxBlPeBIJxBGa2JhITZYP78+axly5YsJSWF9ejRg3344YeR7/r3789GjhwZdf6GDRtYz549WWpqKmvbti2bOXMmq6qqinxfUVHBJkyYwFq2bMnS0tJY27Zt2dSpU1llZSV3mcrLyxkAVl5ebueRCA9ZtYqxUIgxZXGq5giFlGPVKr9LSPhFVRVjZWWMLVmi/KsREwQnq1YxVlAQ3bcKCqhfEcGFd/wWzsMSVCgPS3wQDivbAZhtaV9YCOzaRTPCugZZ3ZyjZrSOleqqrxplriWCiCt5WAjCKe+9Z66sAMC+fcp5RN2Bto5wjlVGa0DJaE2+YkS8QgoL4Sm8yeleecXdchDBgQZaOVhNBhijyQAR35DCIgmKeOGDNzndiy8Gow7pvboPDbRyoIzWRKJDCosESkoUv4wLLwSuv175t3VrMmPr0bcv0KyZ9Xk//uj/AEXv1RtooJUDZbQmEh1SWBxCa+9iJCcDN9zAd66fAxS9V++ggVYOlNGaSHRIYXEArb3b44or+M7za4Ci9+otNNDKQc1oDdSuS8poTSQCpLA4wI+190TwqQj6AEU+Fd5CA608gpjRmiBkQQqLA7xee08Un4qgD1DkU+E9NNDKY8gQYPduoKwMWLJE+XfXLqpDIv4RTs1P1ODl2rtRQijVpyLehLo6QOklCps7199nIZ8KfwjS1hHxTnIycMEFfpeCIORCmW4doGZt3b9f398hFFIGYKdZW62yw8q6jx8Ecc8Tr94rQRAEQZluPcGrpY1E9qlQZ4LXXaf8GwQFIOhLVgRBEHURUlgc4sXaO/lUeA/5VBAEQQQL8mGRgNtr7+RT4Q/kU0EQBBEcyIclDiCfCoIgCCJRIR+WBIJ8KgiCIIi6DikscQL5VBAEQRB1GfJhiSPIp4IgCIKoq5DCEmdQQiiCIAiiLkIKSx0miEnbCIIgCEIPUljqKCUl+mnx581LfH8Yp4oaKXoEQRDeQ063dRB1X6LY7LnqvkTxtpmiCE43kEyUDSgJgiDiDcrDUsdI5H2JrDDaQFINDbeKtnL6e4IgCKI2lIeF0CWR9yUyIxxWlsD01HP1s6Ii5Tw3fk8QBEE4gxSWBCEcBtavB5YuVf41Gjjr6r5EThW1uqroEQRBBAVyurWBiNOlFw6aIg60XuxL5NYzO7muU0Wtrip6BEEQQYEsLIKIOF164aAp6kDbt6+izMSm+FcJhYDCQuU8u+Vx45mdXtepokYbUBIEQfgMSxDKy8sZAFZeXu7aPVatYiwUYkxZAKg5QiHlWLXK3rl2qapiLCur9j209yosVM7Te47Y8jktm1vPLOO6VVWMFRToX8esrmT9niAIgtCHd/wmCwsnVk6XjAGjRwPr1gEnT3rjoDlzJvDTT8bfG/lVuLEvkVtOqbKu63QDSdqAkiAIwl9IYeHEyukSAH7+GRgwQFEE3HbQDIdrBlAr9PwqhgwBdu8GysqAJUuUf3ftsh+W65ZTqszrOlXUaANKgiAI/yCnW05EnCkPHZJ/zVjee09RkHgw8quQuS8R77OsWyfmNCvb2dXpBpJ+bUBJ2XUJgqjrkMLCiRvOlE6uyTtAZ2XZd6AVgfdZHnyw5v88WwG44ezqVFHzegPKuryNAkEQhAotCXFiFV0jgtNIHIB/gB4/3puZuJ364dkKwO2opqBTl7dRIAiC0EIKCydmTpciyHLQ5FEQsrKAqVPt30MEO/XD4zRbl51dKbsukUjwJrckCCNIYbFA28maNgVWrKjtdCmCLAdNHgXhmWe8HciNnFLN4HGa9dPZ1U8hK9PhmAYLeVBdikObhhJS8CjM2nXcyMOyapWSe0Obb6OggLEVKxgrLWWsaVPjHCh6R3Gx/DwdemUsLJST58UuVVWMlZUxtmQJY9Om8dXNkiVi1y0rcz/nidH796pulyyRU3d+P0ciQXUpjhc5qYj4hnf8pt2aDeDZmRfQP8eIggIllFjU6mEVIRLkCJL165XZlBVlZd46sloRhJ2ZZdRdEJ4jUaC6FKcu7w7vFUGW/7xwj9+eqE8eINPComY15ckgu2oVY82a8VtZysrEyhLvMzq3MsS6aW0Ref9uIis7r9/P4RSvLWtGZUiEuvSasjJ35CKhEO/jgwrv+E0Kiw6inWzxYn6FJdZ8byaMg2xKFRlEZG8F4HYnDZKQdVJ3QXoOuwRFICdCXYogS0mUtaxJ1EbWliV+TwYYI4XFEaKdjFeYxQo0M2Ec5BmdnUHEjq+NXmfyQokLmpC166cUtOcQJUgKe7zXpQgylUQ/Fb2gDMZuYHcfOS1BmQwwRgqLI0Q7WVUVY/n51ucXFNQ0ICthXFzMV4Y5c7ztkE4GEVGrTGxnys8376SxdWyXIM6m7QhfkefwU7jr3TtoCnsQ24QbyFYS/do0NEiDsRvwjg9G7TFIkwHGSGFxhJ1ONnGideNRGwGPMBaNQPKiQ3o1iBh1Jt6juFjOc8b7zsy8z7FypX/C3WhgcSqQZZMobcIMt/q3W7vDW90vKIOxbKqq+McHPYtf0CYDjJHC4hiRTmY1wDZuHH2+yBKSyOF2h/RilmnVmXgPp3XgtZB1CzNFOhRSvvdLuJsNLLzv2cslmERpE0a42b+9Sr8QxMFYNiLjR2lpbetlEK2FpLBIgKeT8QywscsUvOvhTZuKWxrc7JBerOPLUuZkWXqCluNGBCtF+u67/RPushRTM6HqxjKXSJuINx8Kt/u3F/URxMFYNrzvqVEjfetlUZH7clwUUlgkYdXJ7HQQ3t8UF+vP6PzqkF4IA97O6FUdxNugo8KjEGRnB78tGR1WypSbPgw8bSIefSgSYbCvC87RTvqOyFgSRAsL7dZsgdXOvLy7JmvPU/cB2r9faRqxqMmUpk4FOneuvVOv6P1kwVtuLzZ15EFGHXi9M7MsrNL6A8CPP/Jdy422JHLNUCi6vVntIWWU4E3dMNJpgjerNuH2/d3Ci/7tNm7s7i4TGUnerN4TACQlAdXVtT9Xz09OVr6Pt/dMewk5hLfh79hR83+RDf2GDFGy45aVAUuWAHPmiJVLdN8Ts/O92IiQZ3dm3kTGfgmlICBTyXCjHnmvWVwstoeU3xtG+n1/JyTCRqNB3t1d1n5KPPvI6SkrWsJhpT3G3Xv2yOLjOm4tCVlhFT2gNcXFmoPt5ibhjVYQNUvznu+2b4eVc+OKFYnvWOcUXrNxRoY/kS8i7VhkWc7vZQ2/7y+DRPHdCpJztBuRS0bviddHpagoOO+ZfFgkYiUwV63iWzvUE/52fCR4OqRoBxE9323fDiuhGUShZIbXvjC8irRZe/UqSkjmO/Tbh8Hv+8siXn23VIKkdLkZuaT3nuIl/5IWUlgkwWt18DpvhFmHFO0gQQ0FrKpSwvKmTVOO0tLaWxcERSiZ4ZcDppFCwHN4VY+y36HfFg6/7+82QRngeAhKWb1uE/GYM4gUFgmIWB38mFkZdUjRDhJUIcsz0ActQ2ssfiex0qtDoyM7W9kXy616NKovnnrkfc9+C2u/7+8m8Rj5FAT8GBvizQJNCotDRK0OvIP+nDnuCyvRDhJEMzbvQO+XwsKrTAXBclVVpbQ7P5VSJ4OdHV8sP4W13/d3A78V73jGrwlhvFigGSOFxTEiCsiSJcpyBa/PgNuzkni3sPAO9G6llOfxWeIR3kGqVz+VUqsEdsXFxs61dgdKv4W13/eXSVAU73jFT6tbUJbFrCCFxSF2EpipG/PxRAy5OSsR7SBBM2M7TYzkpG6tZvMiwjtIliu/lCfejLZZWbU3trTa7NKqXfotrP2+vyz8bDuJUH+MJabVTSaksDiE14k2tvFpFRerc91UAkQ7SJA6lNNst3brlmc2LyK8vdp7Kci+HW7tm+XmQKmSSAOmE/zywUg0f5lEsrrJhhQWB/CEKZsNlgUFjD36qL/CVn0OkQ6id352tpL3xEtkDXIidctrOVm8mF94u60kxINvh8ytFrwYKFUSccC0i9cWlkT2lyElWB9SWGwia1O2adP8E7axzyPSQVaurL3HjNeC2mkOETt1yyuUx4wRE95uKQnx4tsRjxaWRB4w7eCldc6uvwwpAvENKSw2kSVgeRWWIOVjCJKgNhvo3RjIRCwBycliAlW2kuDUCdJL4V5Zyb/JoujhxjIWOZjq45V1zo41h6xh8Y+rCssTTzzBWrVqxVJTU1mPHj3Ypk2bTM//5Zdf2B133MFyc3NZSkoKa9++PXvjjTeizvnuu+/Y8OHDWdOmTVlaWhrr3Lkz27x5M3eZZCksskzYVlFDQRN8QRTURgO9mppfZt3KUFTNhLdMJcFLE72TcovkgJFZ104IUmRX0PDCOifqLxOkSVYQiFdLk2sKy7Jly1hKSgp79tln2ZdffslGjx7NMjMz2cGDB3XPr6ysZN26dWOXXnope//999muXbvY+vXr2ZYtWyLn/Pzzz6xVq1Zs1KhRbNOmTezbb79lb7/9Ntu5cyd3uYJiYdEOlkFyZLUiqILaqAPKrls7y1CxlhavHOi8coJ0mjvF6ZKe+j6zsrxbxgpSZFcQcXtAFE0rH7RJlp/Es6XJNYWlR48ebMyYMZG/w+Ewa9GiBZs1a5bu+U8//TRr27YtO3nypOE1J02axM4//3zRokQh24fFjrDVGyzdnpXIEiDxKKhl162dVPZqHh4vZzNebAPhZOYqyw9Mey+Z2XDNCKriXlcQ8Zehd1VDvFuaXFFYKisrWXJyMlu9enXU5yNGjGCDBg3S/c0ll1zChg8fzkaPHs2aN2/OOnXqxGbOnMmqNNKkY8eOrKioiA0dOpRlZ2ezc889lz3zzDOmZTlx4gQrLy+PHPv27ZOisDBmPXBlZTE2cSL/YOnWrESmRh2vnV923YouY3itwPFEsDmdWTqdudqxUurlYSkoUJQznner996aNq1JSif67PGylJuI8FpP43GS5QaJYGlyRWHZv38/A8A2bNgQ9fnEiRNZjx49dH/ToUMHlpqaym6++Wb28ccfs2XLlrGmTZuyGTNmRM5JTU1lqampbMqUKezTTz9lf/vb31haWhpbtGiRYVmmT5/OANQ6ZOVh4RGAfq4Xytao411Qy3wXQUhlb1QuHmXK6YzKqfLKO5BMmxb9vrTvsLiYXxm3Wn7KyhKrDxnLjfHqS+A2vPXCYz2N10mWbBKhHgKjsLRv354VFhZGWVRmz57NcnNzI3/Xr1+f9erVK+p348aNY7/97W8Ny+KmhUUlqELHLY06nnxutLixdhtEBY5XMBUXO7uP05mrUwEqoozLUOKMtgSwu9wYz74EbiJaL1byN4h91A8SwdIUmCWhfv36sYsuuijqszVr1jAArLKykjHGWMuWLdktt9wSdc5TTz3FWrRowV02N3ZrDipuatTxlo3RzbXboClwooLJrsLttH05GUhElXGR5Se9e5oNojwDpp29j4I6EXITt/pp0PqoH5CFxYQePXqwsWPHRv4Oh8MsPz/f0Ol2ypQprFWrViwcDkc+mzt3LsvLy4v8fd1119Vyui0qKqpldTHDL4XFD+HjtkYdLwJVZHCz+0xByf7LmJhgcjLLlzFztTuQiApf0TQEsfk77A6ievXLs/eRXsRToltf3PaxiLdJlmwSwdLkalhzamoqW7RoEfvqq6/YrbfeyjIzM9mBAwcYY4zdeOONbPLkyZHz9+7dyxo3bszGjh3Ltm3bxl5//XXWvHlz9uCDD0bO+eijj1i9evXYzJkz2Y4dO9iLL77IGjZsyBYvXsxdLj8UFreWIqwG1kTQqGUgskTi5D0FIfsvY/yCaeVK57N8GTNXOwOJqDIu6uCrtT7ZHURlhWzbqdN4xAt5FS+TLCOcll+WpcmvenQ1cdz8+fNZy5YtWUpKCuvRowf78MMPI9/179+fjRw5Mur8DRs2sJ49e7LU1FTWtm3bWlFCjDH22muvsc6dO7PU1FR25plnWkYJxeK1wuKGiZNXAUoEjVoGTpL88b4ns8HJj0HGSjCpSfXMnpt3li9j5ioqAEUHN9EQavV3dgdRWSHbQe+zMgeuePexkO3Qz+MvZWdCpDexEumvfvpeUWp+F3HDxCmqAMWzRi3rnjKT/BmV02pw8mNfEzNFwm6dGLUbr9uHHWXcTqi33UHUaZuzOoJgFZU9cMWzRVhmXehdy2gJUVSO6127WTP+pWu/87iQwuIisjugXQXI6QzYD41a5j2dJPnjeU923rNXdWqkSDi1Onk1yzdThOwo46tWiQl/u33Y7d2n/bYyuDFw8SqhlZX8yrEXirTMurCzjMjbH52WMwh5XEhhcRHZJk5e4VlaWvu3TpxJvdaoZd5Tfe6ioppryB4kFi/m+73qauX3LEUkf4zZoafAyRwgeJQ6O87OVVWKv1LTptG/01Pi7S6rJrKFxc2By0gJVY9hw8Ty7lhZE5y2V5l14XQZ0axN8Fw7O1tRBo0IggWMFBYXkf2CeRWgpk3lDHqinVHGYCVTAOgJLLMdlO2+J97Bf84c/2cpenVi94hV4GSbxXmVOrvOziLJyUQtOXYHn4ICxQIUZL8ztwcu0Taq9x6sLBUTJ8pprzLrwqmSazbx5b12drbx8wfBx4gUFhdQBeHixUoDsCt8YgVqaalYJ3aqtHgVHmv3nmbIjtDIyjJ+TyIWFj9nKbLrRFbobywiSp1X1io7y6o8PjPqMW1a7RwtTv3O3MKLgUu1gonIO21qArtKuaiPlsy6cLqMaCYzRK5t1MbIwuIDbissvLMDK+Fj5HjVqJF4B7YLbyMvKjIfNFas4Le8qEs3TgSAWxEaMnKCuJ3Uzeh8kToRneXLthqJLH16aa2yY0FcscLcqueW35mbeBV+bKcPl5bKd7I3m4wFwcLC085Frm10vSBEnZLCIhGRGayZ8JE5E3YiNETMiGbfxwpsI8tLVZWyxuz0udzwHzDrjCJRQm5arYzOX7FCfNlKZJbv19LntGnu9wEZrFxp3KbMJi1BzRnixcBltw83bco/6eHtg1aTMSuH/qZNFUWKZ7IhGhwg6jArcm29fuO39Y8UFknwOjWpywJOQmRFDqdmWZ5nEi2TUeMWUZDMOr+bERpGgx9vR+YV9jxJ3fTuL7O98M7y/XIu51VY/I6oYSzYFhM7uD1wuR1lxXMsXsxnwVP7qlX/41kiN6tXoHaEm2i0p4iMMOo3frZlUlgkIWuWKds64HR2OXGi+fX/+Ed75dKbhYksQXlZhzydmDH+jmwl7HmSuoksyThpLzyzfLfC962Uuhkz+O6rLhP4bakIqsXELm4OXE77cFKS874gshM7jysArzJnVq9O29CqVXKs2H61ZVJYJCFrlilrZiHDLOuWhcWoU8ga+GTlXbF7b97IE6dJ3dSyyFDQnLQXN5YIrJQ6K0VaPdeNPXkSTfFwglt14WYf5u0PV13Fd67W36y0tHa4PE9fiK1HkVwzolRWmsvtIESiGUEKiySCZmHxMkooPd1+ObUKHI+QEglp5jHTitSn7E4sK/LAqZIrw4zvxhKBkVJnZYGS/bza9+R0vyk3STRFymkftmv9FT2cTrrsRlg6ed9++6LYhRQWSciaZcqYWcgSoLwDIW/kklXHZUxuR9ITBGazH1kDnFN4w9eLi5XznSq5ssz4biwR6AllGYo0b3+Uaep3E5k5cIKEUfI3XtnCu2xo53CyrK1ONuyG5ct43/HoV0UKi0RkDbZOHCiLi+XNrNz0BTEbMGR1JNVEO22acpSWiuWy8aMTr1rFWH4+fx2q69p2lVw1KkgWIrM+uzNEmQ6ZZhZP0X6oOtWr7cwrS4dXuWj8Qm+5hHdy6JbzrtPAAbVd2N1qRdb7jjerHCkskpE12Ipme3RjUHUrn4l6WKVPd+pcZhTiy/NMM2Z434mNwl95BJpd8/myZdb17IZQczJDlKlIG/mUyWz7blk6nPhMaK8RTwOWCu/k0K1Jl5G8FbG021k+kp3zyCletx9SWFxA1ktUr1NUpJ96vLhYP0GYzAa0YoU7Hd5NQW41A7n7buuyWe2rIRurBGM8Ak1UyQWsc+S4sdRgNy+JCs+gwOsMbmRhkTnQ2bV0mPVl0XetZ0nzYxlJpnzimRzKdN6dNo2v3LzKlJ1ADS+S9vHiR/shhSVO4OnoshtQVZXzTfLUSA0rQS5TybOagfAOZmb7ashk1SpndRzruKzWo513p30nbiw18GR+LSiwXlLhDQ2361MmeylBdOZr1pftLhk3a6ZMfsrKxPP8yMCOfLKSC7xyUYYDvkiY78qV1sqUHeXDaTSqLDnr1zIkKSyS8NO0WlVlvO+G3QZkZ7auN3gAxgqLeo7M0FPZJmC3fQCsQgydCFK7g66qNMg2PdtVzIzagtUM24lPmVtLCTwzX7PBAHAWlacedrYLcIKdAU6mgmPUVnjD483qw2z52UrZElWqnVhYZE1o/VyWIoVFAn566PM4adqZ3YnORvTCPQsLxTYw4xVkZvg9MxZBJImTnbK56TStHrxJ2Zz4hJi1BauJgl2fsqoqc0Xb7mGVh8ltvzGRQ3RZwehd8DxTbDt2Q8ExU2Z4rMB6OLU0iCrVdqNRRctp1q/8XJYihcUhXpnG9BqQqGLB04BEBaa2g+h58/OmTxfpfHp1oX7Gez+zXbS96HxOIsG09WM123Q7+Vasw6eRou5UeXKiONqxfjpdprPbjrxQMnkPkS0NzJQF3mdSd6xWo4BE2oJTOaxaqWPbs5lyK8vSIKpU21VyeMtppfh5sVu3EaSwOMAr05heA8rPF58B8jQgEYEpOtuxe6iCTFXSYq+blSVWFwUFxmv4onWnFzrNm2vHSZ1kZfEpw7LW7522CVmWLy+cCd2wcvDKgiDsoSNa11bKwvjxYvcVTR0vUw6LKLe8spLHCmk2CeN1ujZScnjLOWeO8caR2n5NFhYPkamwePHiZMzEzcoR2ykWL+a/npFTqswyaw9ZJnp1sDczBesJHb3n1Pu9lTIhYxatVx6zNiQ6ADdrZt8642Tt3epwupmn2tbNcqW44QfFa20NioWFZ6NWtU6tlIWMDHfKqLYFvwZQXuWS1wqphcfNgFe5EpHpVu24sFAsD45sSGFxgNumMVkzPbN1TbtZJAGlI8RaGN5+Ozhr8Gb1oQ4g77zD95tYBYFnycBIKDmdRdsRBup7Ou00vnsUFTm3zujlj3AzUiP2ea2iNrSHdjAwmmU6eV+8S8My6km2743ZAOungqW2BTfkMI8yYPfZ3faLib2WEz85o3p34tDuBFJYHOC2Zi9LGOg1IBlWkOJiZ8KxaVM5u6rarZPCQv7ZR2zoME822oICuYJOPSZOdL89meV24d3eYMmSaMFfXGyuAMlIpW9UZp72EArxRY2YHWPHOs90a1dRzM5Wyi/SJ3ly/8QOQtp36sRHze4R2xZky2HeIAonyqWR719pqbzlLbcs3dptBbxO7U8KiwPsemzzImM926yjObmu01nc0KHe+VWYHaNG8Z2nFXZ2Bn6Z9W+3TfG2p6ys6OvHzjZF9jri8Tey8kESmbU5FdJ2k/eZvW87iCpd2dmMLV/O/+xqnaqht4sX8+3ga2WpcvvQawsy5bBZ+zGb+Nltc3p9REY7czPaTFXC1XYzZw7f8qEMSGFxiJumMaczcaN9hWRYbuxsIqg9nOYekXXwbNzYrFl01lsRRdLIDO10YLUzMPKGmKubKhrB47eQlWVs1lbvobW6mJXHKKuzaLncPNxYtxexTk2fLtYns7Nrksip9/Gj3njKqf3baAYvQw7bCb9mTLFqxSq6bk/GVLlitHTlxvs0U1q9SuNBCosEzExjThLK8cwc9JKuWZnlnFpueK0SRmUOirIicmg7pFMLi1m74T2MstsatTHeMN1Y64pRuc3yVqjXMWsDBQWKv5PVIJueXnv5za3QaSdt2q11+1ilRa9eRZZVhw7V3+ZDtt+OjDpVHTx55afTJQqRpSX1vfhVb6ofiZHi4EY+KnXJ1Is0HkaQwiIJozwpTjVRnpmDqFLkVLAPHuys0QdNOIqUXa1vJz4seu1GNa3+5S/8AosxZbajNwDpmcx5rsub6Mro91lZ9pMF2nkXWrwKCY71tXFr3V5magCr+vSi3mIPdVlYpnXayQTx+ef5yj1hgv+WPKutFWT3wcJC641j3YwOUiGFxSVke3rLdG6qrHS+Vm+30YvE8Qft0HZIHudMuwKXdz3erAzaNsZb306XggDle1lhlLzvQmXYMOfX5bFW5Oc7c6rlwS2HSbMjOdn5PdVoQZ5zjawEbjtuGtW3jC0PeNuu3d+pfkc8/ZBnUmV12Fk2dDNXEiksLuBGQjknM4dYvFQYZsyonQyptJSxxo29K4Ns5czKkx/gW1oxgseqxrOLttrGZIV9iiSg8urdqsKxslLOAP/b34rd1w389MVR25nZ31b1IuoEK1O22cFr5dDuliWiEz4nCpie0uhnhlsVUlhcIAiaqBleZtO0Svks8zAa4FeskBt+KTKDtIuVX5RINlA77VFvEOFtN4sXezfgqsLRiV8VIK7UXnwx3+BqZzB2I3Ed77lFRfrtzmr3ayBaSfcrT4dofXupHDZtWpMJm0epKyjQt+TJtmDGOsI7zTtDFhaJeKGwuK2J/vgjY5s22S+f2z4Geg3Y7iyGN0um0eaLdhxlrY4bb+Q7b+xYZzNGGREAai4UkRmvke8Vb7tRE7V51baqqvgT4gHKwPH228pg4NSfyswnza4Pm+wJhciMXmv+19sk0Or32mfzernHTn17vTytHcztKnVOLZixyjnvO3E7jQcPpLC4gNuaaGGh8vsPPhD/LW+0iMzD7ow7O5uxY8f4O4nZ7IonyVOzZs7DtfUO2SF/IgOaNgEcj3A0870CjMOVte9CRq6OJk0UkzbPe7cz6GiXLpyU02hwceLDJmsQFZ3RWw02VVXW+ZdiU/rbsTDZ+Y3d+vZ676bYSYwdpU6GheXRR+0twfllOVMhhcUF3NZE1euIZjz1a21cdEZgNIg67SQ813FDoZPdmXkHtOzs6DZmJRxF8qsY1aFR2KNIXYnWp51BRw0TlvV+Y30ynPiwVVbKCf3nTXLG2z5FFSk7irodK4mT+hbpSzzLYnbqxusoT0BRZkXfjTaUmzc/jmxIYXEJ0YyJvBw/XnOdSZPEfuu1+VMVFKIzAr3GL8u8bHUdtyxQZkJTT2DxWIus7jlhgv5vja4rEk1k5ufgdruKfe922rUby6KqNcuJhVWWn5fRBpxO+pGoYiiiqFdVGb8Tq+s4qW8ey2t2dk3iSKeZbe3UjVGZnbYRkfvrpU9o1kxRXpxuRSECKSwuopcBMTnZ/l4wjDG2Y0fNtcaNE/utl+ZPbYfkFSjTpllnMpURTWB0HS8sULFCU28A0UtVHzvLFPEJ4p3p8raPadP0E3o5UYitnsVs92CeQUd7n4ICd96z6pMm4pys3Th0+nT50SorVvC3fyvsvl/t0pQeq1ZZh+CaKfxOfQZFLU9GSp9qXeR9h7zLcEb+RDKUJp7ldKsUDlaySiaksLiE0zwsPA6X3bt7I3DsHHpLDbwRBn5ht36mTVPWpnnOXby45n4iQkev3fDOxt0w+esJJbcVYjOfL96ZbyjkntO5qIXFi7wfycnK7FgGIoohb5sRHXj12oCIQ7FZ+xGxPJkpEqL7rBmVy2p5zM699A49i2mzZoyNH8/YyJHi13PTn4UUFhdwuoZt1lDHjeMTBNqyqB1LzR/iVs6Be+81nrWJRhjw1LHs3A12B1yR0OHs7JrQZDs7Cse2G22mXJ7N66xmcyKWilih5LZCbBVVxyPAJ04Ue8+8A4JW4XY6sLtxyBo8nCyJaNuMmo9J1Mk9dkuK0lLFQdvqd2rWaaulVqcyxU6/Vicx2vsb7bEVW4d+5uuxetduRAyRwuICTtZUjcJBzQSE2ojVnVfVDrd8ee1BTBXAToSpUTZQK8XJan8ZkR1V3dh8S3TAjTWp8gxS6rtyMsvXazeyItNEBiQjZ1O3BmqrsvMI8MJC/t2mhw6tWZ/nCX/WW7ILitIic/Bw4mejOm7b/b026k3kGkOH6lsSeOUGrzJjR2nPzlYUad7nUfsdbzv285Cdk4UUFhewu6a6YoWzrKwiv41VHvT8JvQ6CmC8w7GZKVD2gCpyb16cWhh4zduhEN8u0bzthjH7bU5PEIsOBnq5JZwIOb364hlweduYqKWxoEDpm2bvTK+MbidKFD1i+5ZdiwKPz4nsQ1u/MtsYj9wQmSB56ScoMxmmW4fsrLeksLiAncHZ6/woelkUY02Ses6gPAJAb3CRkUzP6VIbD7wzY7Nt7nmz0No99AYe3tDx2DZnJIirqvgFYuw7cxraHPtOeRVRkTbmlgVE793YWfpw49C+J7tWSq8SAuodxcXWS59225iR3BCdIHnpJ+hEYfHK8kcWFocEMQ+Ln/lReD3UefbPMWuodi0s2jLwpl932kmMhLlV6moVtzb/czqLj81mayWI7Sredv0b9JYKRELXRcvrhgVET+H2Op0Az3PbsVI6tQDbPXisvzLrR8XOBMlL/6Xp0+23X7v7GYkcqt+QTEhhcQmRUDk/1yLVWHqrQVhU6OotPYgm07M7oEyb5l7oMw9uDFBOlqDUQw2n5xXElZXWwlcbhWJX8Y51JDSrd578NCJtTLWApKXJeU96yrLX2VTNntuulVLEAixzY9M+fbyzBqhh84sXK5O5v/yF73dz5tReUvXCf6mgQMziFSsXeTZQ5W1fep8b5QJyAiksLsITKrdqVTDMxWoHMGpgokLXKCkWrxIna53azZwARrhhMYttN3buIZrKvqyM7z2IWmSsni22Ls2WKY3y0/C0MRVZM02j0Hw/LSyxz23HalZVJeazUlQULIdj3kPGUlOzZooi4JX/UlmZvbBuqyAIqyM9nbFly8wj89wIbyaFxWVil1W0fiMrVwarU8twmgXMkxHpdeTs7Ggrj8wB382cAGbImL00a2acLM3uIKi+D55zVSuZ1VKAOiu3sxRWXCwW3s/zfkUSNlZVyZswFBfrP4eXywSxzx27lMn7jrQW0mHDxNuY0bKq2V5UiXRMnOhNSgnt5qZm58Um75Nh1Ved0d32K9RCCotH6HVgo/Bg0UNmJzBqYCJhu6tWWTt0lpXp70mhCliZnVqk08jK7yJjVm2mZNldZlAVIJ5zRROh2dkzStTZ0eo6Zr9z00nSKvGh28sEeqkNjBKCibx7qyynsUesb57ehCUerS92jtiEfW48u+h7UmWw1xFGspxvSWHxADdCPf1oYFbPoa5Z8jj1mZ3jV6exipwQUWac+C2kp+unVNeW4aqr7F2bZxO3WEVCJNW8nVmkqLOj0WHlGK71zVHfo6jgNno2Hguem8sEakJC7b3sOj+r776yUtzJ1qwezCYqiXjEbj5q1AbUtP6xn/NYNUXDvFUZbFd+2D1khTeTwuIyTpc3eNN3N24s14Nfr4EZrVc2alRj2udx6nNrLxcnncZKydITKGb+MU5n7kZpzJ3Wm/Z5zHw9tDN1kZBpO7PIWGdAu3XHq3zYGSz79OHzSTOTA2VljD3/PGMZGfLbtnbLB16ZY+XnI2Ixs9oCQK/umjVzPnBmZyubfOo9j96hWnDdCI/WO/QmSUYTH9UBPHZvKbP3ZGd8CYXcT73AUw92IIXFZZwOXLye6m43MCstXtSpLwjPpCIjukXWNY2uLTtZVmGhMsDInu2pZbX77AUFfFll9Q43zdy8UUx6eOGAqfWf4e2DsQO2uuO2+nyDB/Pf32yTRaP3qbZnHr8WK8Vaz2oT+zza9+WVnIrdSkBbltgNRPX6o15It1ZJdvIcXuxlpZaXfFhs4rXCYndpQB0E/Ah5NsotYFXWqir5IZwyBmkrHxYnnV6WH4bZtdXwYtnvWWvRsOsIrp4bm6PGbsI0J8sYbvYVu86DMhRNnqzI2pwXIkt4VgMmz3HTTfrPzWvlURUWI6VET4E2Uqx50zR4FWpeWmpcHzwWcaP+JeM57E4MRA89Z3e7kMLiMnYGw1iTn9fmu1jTroiTpsyZi1EY69Ch9urSCBnCy8h6IyPZlqgzK+9hlCvH7Dexz6I3A4zdUdaOo2FyMt9v9MzjbvpBTZvGb1mRFe129tl856mDo5cJ/5KSFIVai51r6fX12B3feRRr3qhArywskycbb2TIe5gpy06eQ13CdXubBbKwOMAPHxZRhSN2XZwnRLagwLzhhUL8JsDYwVckDJa3rLxOn3omeNEQay+El5F/jIxrjx3rjiCJfc8i0UC8O8oy5mxJxErQ6+U18iIKhSe/j9fLo40bK/3Py0zbw4ZFP7Pda6nhuTzLbXaT3+ldI56CIfQsojzJHXnev1uTIm3ZZUAKiwfwDOLZ2cY5NxgzD1sLhRi7+25jhUQV4LwmwNjBl1fw8qbvX7nSXoIvFR5hE5t3wAwZwkvtkLECRUaaftnCRC9aRjRHh+igodbL4sWM9e/Pd5+iIntbJBjl+pFdh4B5WfzKcDtxolj6fSeKlV1ZEXuIDGh2EqXpEW/RmxMm6PcHIwd6o3arJ1/dbqsUJWQTv/KwWMXJWw3Qb7yh/7uMDMauuML82mq4segMOjaRm9WMjdeHQBUkPEnkjHCi8Ihcj0cAaMML7ea9MLu2nVmU1XWN1v9535/dZQcR87PejJLXtGxnJsq7DGV0xFpd/HRAv+ce/Yi+pk1rK1lOBqtYRf3ii+3VG+97FdkigGeQ9CojrVuHmZ+PlcOuFrfbKllYbOKXwsKYYlnQm+ndfLPxb4wGwXPPVf7P48mvCgQeS4JepkyevCnFxfxLF3qe83pe/qpwFcmEKrJZnt71RAZUrXLk1mxNfX5ZSx2hEGPXXOPMuVVkkFPftWj96OWwcIqVkisyUzWrI63fRdCXHeyGFodCyrOVliozfyeh2toIJzMFVXS5ySjzcCxOcxv5fRhZTI2W1I3qwA1fFrvO6kaQwuIxagO68MKalzp1qv65PMnVeDdt01o1RIRy7KAcu7GZnZ1URUOmzTbRkpWZVkUk0kRVjmRuJaB3aJVGr2aDVpYrEQuLnfoZP17uezVTjLVKrtGkQuTQ2xU7yEqL3bYhawdlrVJrlutINApM1NLq9yaVTg+nVgwR6xVgvcmlXWu3GaSw+MTAgTUv9k9/qv297EHwtttqri0aYqfVkvv1q/m8e3dnzl4iz6mNBFF9IebMMff7McMoJwKvlWjaNO9yOsRGwrjtIAeYD+ra92b2/lXLnp360duywYnljCf8VaZCGLsU5rZPjZeHLEVFW1c8iRvthMiLzO6DnEOK5+D1E9Gb5FVUMHbZZWL304bFW0V5yYIUFp8488yaF3v55bW/l9151AFvyRLG3n032nwoksm0sLDm75QUsfvradsiz5mVZTyg8A5oVVVK54oVfqKhx9oByauZmVu5bqyEkZlzq9k11AzIMhyPY5U2XuuLlfVOTXgme0lPm3lWbXcynLELCrxPc6A9rr9e7u7yycnKrr9uWg6NLA92/Jxk7f+mPrv278JCxbJo93qxEVu8sq9pU8Z693Zer7Kt3XqQwuID1dWMNWxY8+J79659jtuDUkoKY8uXi93r+eftC3WjnAojRsh7Jivzo9HWAqL3iA25djMlvJ6Q8GImyGNe5jUhiyi2VnWvp7QaKau8eWXcGDDnzDGvO7vvsLjY2aBWFw+jbUZEIm7Uz6ZPd1YWrcOzns+J0749bJjx5IJH9t1zD2O/+Y35ObL9UkQghcUHfvwxugF06FD7HK/Mk2rqap5z7cwKx451z+wu0pFE12eNrq/15xF5joICxT/CaRmKitx15uQVRm777dh9L370Ib1jwoSaetKbdYq+w6Qk+UsxdeXg9Zkzi7hRJ1x2J5J6fnh6bUNG387Pr52bSOT3w4ZF14leHcle6uHFVYXliSeeYK1atWKpqamsR48ebNOmTabn//LLL+yOO+5gubm5LCUlhbVv35698cYbuufOmjWLAWATVMnASRAUlk8+iW4E2dm1z5E1KFml9RaZYaqWhNNP5y9X7Fq+F86HeqZKGYOrKrTsKB6qwOLNIWF0qNEzbjlz8gqjoK336ylasq2Uf/kLX5p89Rg2rLb5XUYWYDrstwne/EF61g8n7T42dNvMwVjW5MpuQEBubs011P+rhxt+KSK4prAsW7aMpaSksGeffZZ9+eWXbPTo0SwzM5MdPHhQ9/zKykrWrVs3dumll7L333+f7dq1i61fv55t2bKl1rkfffQRa926NTv77LPjUmEpKVFevhpGlpysLBOpaCManDTaiy7iP/fuu63PadJE+feyyxjLyRETFl7OyGOtOk4HV+317KbaVwemFSuc14NZHhs7UVvaw2rfD7VtupV91+mhVVZlK1UynJ1jZ6hWlrqCAuv3qSadVBM3kgLk3Opm5vdit45VGWI0adGW2enERm0XdjfPVZeFHnzQfb8UEVxTWHr06MHGjBkT+TscDrMWLVqwWbNm6Z7/9NNPs7Zt27KTJ0+aXvfIkSOsffv2bO3atax///6WCsuJEydYeXl55Ni3bx/XA7vJ3LlKY/jjH2sayOHDyndOl0yaNKnxGfif/xFr3Lznjh3LWNeu0R3NSlj4MSNXZyxOZ9paBcHJdVQlTt0Hxe7AolWgjMzKWu99kWvrZad1ujmel0dsjh8Z5VXfmwznYe319LIAz56tDDLTpikKiJ1kjDKtNk73wbJTNzKuY7RTs2j+ID3s1nFRkXWuE9ltze7xpz8p/55zju1hzhVcUVgqKytZcnIyW716ddTnI0aMYIMGDdL9zSWXXMKGDx/ORo8ezZo3b846derEZs6cyapiVLoRI0awoqIixhjjUlimT5/OANQ6/FRY7rpLaQx3313jfPvvf8tdMmnRQokGcqMxz57N2KBByv9vvdU6nK2qit8xlXejN55DFSp2ZyuxDrYyQ15lhLpaJdZT6140qsOofPFw6PkriL5zvTYkkinaTlmNlgh4HWy1A6zZu5MZ5SLr0CryRrsy816rcWNFydO7lrqtg512FIvb/cOL1AVmx6RJjNWrp/z/m284BjWPcEVh2b9/PwPANmzYEPX5xIkTWY8ePXR/06FDB5aamspuvvlm9vHHH7Nly5axpk2bshkzZkTOWbp0KevcuTM7fvw4Y4xPYQmihUXNqDhvXk2j37hRbge48kr3lmFKShi7/Xbl/2o+EiOzoWjHfuYZ5V9ZilsoxFhenv3fiyZK4znUwUUvrJJ3g0rtYZZYz065i4r8XVZwmoU3FqtlPKsBU63bU6fkDviqpcxo52GRI3aAleHgzXs0acLYo48qjsaxSjfP8mRsdmA9WSKyPG62KadaJqP6NvJ7MXKcVi1j2dnm71DUUvWXv8gNHxc9CgpqcoXdf7/ZaOYtgVFY2rdvzwoLC6MsKrNnz2a5ubmMMcb27t3Lmjdvzj7//PPI9zwKSyxB8GHp3l1pCC+/rJjcALHlG95OK+oHY9Xp1OPRRxmbOVP5/003GT+nqMUoK0tJYBSkNXhVkMp04DSavVVXK5Yxp2XVYqfc8ZbUjCdywWgAj/2tmfL97bfulN/pskusQ6dX/mJ69a5Xf2aTloyMmqzGscqm9loiFgezgV4NjTcLXY6NsDFyjo1dejW6pt/9w+6hWrY6dTLuV14TmCWhfv36sYsuuijqszVr1jAArLKykq1evZoBYMnJyZEDAAuFQiw5ObnW0pERQVBYmjdXGsIzzzB21lnK/++4g19IOO20eoeob4WqCJ1/vv4z2hGaWVnK76wcetVDm8uG52jQQOx87WxLhoXFKmT4/feV81JS7Ckuav1pWbNGrHzxpqwASpmtIheMkmYZ5QfSG0CffVb5zemnB2u5LNbC5pW/mJllT6/+y8rM9x2KjaCKrWOZgz9PZlarrVFirUdGmw06DZ7w68jMrFkW+uILvvfsNq463Y4dOzbydzgcZvn5+YZOt1OmTGGtWrVi4XA48tncuXNZXl4eY4yxiooKtnXr1qijW7du7IYbbmBbt27lLpcfCotWEL71ln7jOO00vkbkNHGR0aEVFDyOYapS0aRJdISTil2hWVZmL+uim4c6ePFsHHnPPfyzt1jU/Ae33GI/Gqe0NPqaCxaI/f688/ypYztLYeoRm1U2Fr3BL9b/x2ofG8ZqTOQPPKC/J5ifh7ZteZV5OS9PLGqEx+Kq5kGxq5zwhp0vWSJ3o0W17EDt3bBlRPzIPG64Qfw3997L/57dxNWw5tTUVLZo0SL21VdfsVtvvZVlZmayAwcOMMYYu/HGG9nkyZMj5+/du5c1btyYjR07lm3bto29/vrrrHnz5uzBBx80vEc8LAmtXClvF0zV9Gs3tBbQ/12fPtFl5o1MUNfz9+6N/r2Ik62eIBFxsuM9eBVCozIxZi1w77675jyj/AWHDim+KrHs318zm9FG8osqftOm1fx23Tpn7SJeDjMHSaskYWY7bWvP+fHHmjratq3m2mqov9+HbGugjLqPlQm8CoCTtsir+FqV224d6kWAubELcuzRpw/feU2aKPJHtExnnKE/MdXjs8+UpX03cDVx3Pz581nLli1ZSkoK69GjB/vwww8j3/Xv35+NHDky6vwNGzawnj17stTUVNa2bVvdKCEtQVdYli+33+j1PldNsE4F0pw5yiD86KPK323aRJebd4bWrp3y7zPP1PzWqfd8WRljzz1nXRei9fi73zkrk4qZMqUObv/+d81y1Q03KPX9wguKBSUUUvyWtM3v118VJ2mAsb59o9+F6ExPVVjUXD+AvNT4QTuslth4koQVFPAlEps3T/n7vPNq2rnfz2/UVt3MhBx7PPccnyx0W4kSiQBSky+ePMnY0aP65ZWVCoH3uVXXACcHj6J3yy1KuZ5+Wvz6OinRanHihDI5DIWUCZze5MwJlJrfJaqq7G9SZjRLUGd8TtdEVYvB4cM1n2nz+fF2fHVQVt2SnIRlawefzZuVzzIynCk/anRQKMTYl1/au1Z2dk2n482SybOM88ADyjW3b2esS5ea369bp++0yFvepUuV62pnXJmZztpLUA/tMkh1NWObNjH23Xc17VjmINm+vfLvvHnB2pYg9tBaA53UK68v05//zCcP3V6mKi3lv0dRkVI/qi/NZZcxtnZtdHmdLuOo78Gr5Tne44ILlHK98ILyt4g1a8oU82W0iRNrR9ElJ1snoxSBFBYXcLpuaeXl7tQxUmsxUPOePPSQ8rcdQVevnuKUZVeIx/p3HDlS891//qOU929/E1vWmTOHsSefVP7fr1/Ns9lRqFRfBpkDYHq64nuhKqc5OYp1JPbdqvdesYKv7DfcwNgPP9T8vWKFvDLHHqJOzLLvrfUvUZcgU1MVvx3G5A8W9esrdRu0bQm0h9q3q6rsZzxWMzLz+IM0b87YsWO15V/soOZ2nYkkSVyxQr/tXn+9Yu2UsYwze7bYxqiAMrjLsIrFKiGhUI0sDIUY27dPUTQBxq6+mv+6OTm16yU/X6l3bRJUvUOW0kIKi0TCYeWYNMndzgnwhyDHNtxYE7qaUTEjg7Gff7avdPTsKVYO7d96+1Oo4d7q4DN5svJ3587mwkT7jKNGKZ9p/TpWrapt+bJKZy/LsmV0nH9+TV4bo/vz7mGUnFyTSblzZ3dnePPn1wxM997r3n2MDtVE/cUXNf4/6jFrltxBMilJiXARyZZq5xg3Trn+Qw+J/7ZpU8XSUFXF74emd6jWvx499L9X+6/aj556Krp/6Tkvy9iSwuwYPpxvQpOfryyLAIpz/9atipxQB/kLLpCTtM3vBH1z5tTIvwEDlHfTt6/y9yOPKLIBYOyll6yXD5s0UZR1J+VJTpazPEQKiyS2b2fszDPtLwOpB284sprci1dpMYpSCYcVhyqAsTvvdL8jTZ1ac78hQ2pSkMf6Iaj+Nfn5jH3/fY1zY0mJtRVo1SolyZcayTRrVvT1jx+veU/XX8/YTz8xdttt5p0yFOJ/tyLCasQIvgFQVcJWrlSyeeq1m9atoz8bN87dma12Nu/HEkmHDkqosbpNxKBB0VF048fLXw5r1qwm8aPdI7aPq1a1006r8W2qqrLve2R3cFEnHSkpjP3v/9b0uVirn5r2fty4ms+6d1cSjJk5L7vhTC96nHNOTRnff1+pa71JjF9Ho0bOIubUY8mSmmzkM2cqz6n6rWif9eBB7zbhnDPH+ThLCosEDh2qcUBVj/R0eyZZ3jVFo/TpDRqYb4+ux6xZ3nXIwkLl39jOERtCeuxY7Tpt2zY6DFVv4K5fX8lhYnX91auj35Ws5xNZJvmf/1EUK15hWVws1qbuv989B8wWLeRtLinjOO00ZRBdsqRmZhnUo0sXxrp1U/4955yapZc//zl6KUVk81Inh2qV3L8/eo8woMaHS83oOmeOfkZbniM1VWy3a5FDVLkbMaJGjsjqGzwbVYq8E6dtTP3/v/5VM05pLZHqUrlaD25POjRZTmxDCosEfv2VsaFDlRmJ6sg1a5aYH4uIpSQ2bO7ddxlr1Ur5Tp01WCXB0p6zaFFN9l2/Dj0L0PvvM5aWpnyflKQoGXrlX7JEWTO2coiNvb66wRcgT9BoZ51WR1mZ+4O9Wdiuk3elrUc7SyROwsx5jiZNlIieyy5TTOFBmUEbHfn5tbeQ8GJZIbZfVFdH5+lQl2RlDmhnnsnYa6/VKEAPPKAsxXhV17m5itXWiWVQfTennaY8Q1mZs2U4t47YTOSqzKtfXxk3YuVpaal7WwKQhcUGbi0JhcPKDKWiQumAZn4WejuJ7trF2BtvKEtLRsnhzJKP7d+vRNfwoieAcnMVQS97Nq5NqGTlKxLrY/Pdd0pZ1VmCHqri8sIL5nkxYq8fDjP29tuKpcOp31Hz5mLbwquhlW76Q2iflychIG+5YzPD2sm5oy75ufnsein37eYHklEeQPH1WbGCseefV9rrsmWMPfigP2UC9C2v4bCS4HLjxhpZIUsm3HmnMsHT68NOFSKegfYvf1EcpxlzNllYtkyJ6Nu3r+YZZPflu++uXSd5ecbJKdVj8GClna1dWzt3SlWVMs7s3KkvS92aQJEPi03cjhKy6txWu+tqryOyrCOjjLKEklH6c97OIJKMavp0/aUhnuvLnDWWlopFWK1cqZTBi+UUra+Jk+i1rCzG3nmnJiLDSd0tXuy+CVpPAXZLQRw8WJlBHjtmvQVAbBv22v9HdSA2sry6WT6eJH925ZDRRC/2PajPbKctqO/Ri0gobTZe1Rq1eHHNhpmx7yXWnSB2GZwHt/oHRQnZxE2FhTdPB286a55lHdHf8JQxK8uZCb20VL8MvJ1BzWFgxqpV9tfDlyyRv0wiMgBrO68XA1ZsfdpV1GQuUag+WG4+t/ZeKl4kMDMa0PTwy/+Hd1Igq3y8ss9O21SvzbskM2eOmIKhJto028xRGwklS66YTazU+5WVGUcvGm0V4MX7Vg/Kw+IQNxUW2RYEUfQathonrzZY3k79l7/IF0qy6sfpQFdaKl9J4A2FnD5d/3nMhJy6x5CTsukprjLCN522ES/2WdEqbFZOyNrst04GnqIivgHCyYzWSd4Oq/2XZJTPbp2olkCeCYl26U+krLwKRnZ2jVVDVVasIqGcKiyxS7lm9xMNF7eyushy0r/4YkW+UKZbh7ipsMi0IIjCazHgdagSXevn2dyPZ7CwmoU5SeokOhPjPQoLa/LZ2H33espmdrYikGRYYfQElddZOPXaiBcWplgF2GjpgWd/IRn1rsXOjDZ2cLRTTp4drkXLp1pneZcqjKxQInWfnV2jCIn0azt1mJ9v7YOXlSW+RK13HbV+rPqG0c7XVs9t9u7N+gdQMwHm2fFaNqSwSMSuBUHbcUtLa9JMiywDyRb6qhWCV3DwNlSewUJGHRsdojMx3mvKsB5Zpb12KgRj69fr5QhtG9E+a3GxO3kgtApwbN3q+QDEtmEZPk5W7Zp3F3CjcuqVkSc1Am9/451xa6+n1rXVUkXs4M+bYK5ZM/3QalWhEI241GsLfh2qIummBdRoYhjbJ3mUETtuC04ghUUidiwIVkKRx3FK5sCjZ4600rRFG6qRNYHHZOxU2Sgulhcpkpxc4zwrw3pkhCyFVC8k3q0QRu2hzcBq9P6zstwpi2otMfMBMPP3Ki1V2svQofb9utR6V/OZGFkUjJR4nnLGKmM8gzavRZNn2S52MLPTZmUspdj5ndZpdvFi51uf2D3UnDde5ERRn1uFx53AbWWEB1JYJCNiQeAxffLMhGRZDIzK6IbZTzsLixUQTZsaR1P54aRo9I5WrIgum1sKHu8z8+Y20QoqN31IRNq8bOsKoChBRjum61kErBwrVQFuV+E12idKrReZ/Uwke6uR1c9q4DSbZAQhmSDvoV2m9bPcbuRM4nluKz8ZN5d4RCGFxQV4hI/IDMTKhGdXgIqEXrph9rPqnFlZ+iZIGflEeA4jc7HZQGJkPYg1f5spZbHwKqR33MF3ntbh0skmeTz157W/SuxhFtlk5HNhVB+xjo4yLALaAcFpP4v9/fPP85VDz6/KaXqGoO1SbHZondL9KndWlvv7LcUeahuTGdnqNqSwuISV8LGjyVuZ8EQPo/BjL+AdvPQ0fC/CYc0GEiPTvvbZYv0zzASVrCU/3pT0sQ6XMmd1o0bJbfNBO1QBbmS5sXs9p31PTx7YtbDIGMTi7V27sSO7aDvw8n7q+/M7slUUUlh8wo4mb2XCE+kcfmvNIoJBr6yrVnlnGYi9r54/hJOkYE6jq7QHj9Mh79If775Wem1ULbdWseONpIqHQ7afgza5n+gkwq48MJIDshzInVqhjJZW3ThkW8+Cfqi5UfyMbLUDKSw+YdfC4tSsHpR1SVGFTc8apHWKnDZNSbNvV9hMm2Y9SFgNDLHr+U6Vsth787xb3igJvcHKzJLEG7FgluxK9n4+TvKQBO14/nnjOov1ldLiRB4YyQFZg5jTzLVGu0S7pVBoo4bMfNES4VDfvUjyvCAsC5HC4hMiMxDt4OLUZJmdzdj48dFpnv1oiKLPEetvY2TVsCskrUyeIgODWjZRpcws3L2sjLEZM/iuU1zs3OHS7vOvXOl8xm8VZqq+Xyd5SNw67Fil1Gcy+94oW6gTeeD0mjxtx8nStSqfeKOqZB1lZcZ+iIligdFGrvE+j51U/7IhhcVHRDqe2lCcOIWlpwenIbppKRIVkllZclNWq2UTjcDRzlj1noE37HfJEueJ7PRYsYJPqPEug5m9T7MoMqs8JH6FparHnDnubLKohtBrcSIPjKx6PJOp2FB1PbShwnPmiGfPNlOIjJzb9dqW6KE6pestz/GGeTs9vFKIVOWMZxwKgnWeFBaf4RlctY6ZbjmF+dEQnTrPmvniaIWlkaKmrV/ZKdRDIf7BWys81HpxIrDKytxxppPZ9syUEKN3yZuHhHfWmJ7uzsCwZIk70SbqDt8y34lZSDPPIGaUz8YoLJzH74w3P4x2OVhVnmQEIxhlAba6tl3rWuw1li/X95MTSYon0lZ5nk3k3bgJKSwuwutAx5MZUlUoKivldAy9g2fWJBunGVyBaKEbW+e86bqNBLcqGG+4wV7ZeGZjWiHg1Cch9jpGAo7HhyW2HcgchI3M/Vbw9ik3lg2sFF9tW3JrYmEU0WP3Oc0sbHYHf7OwcN5rmIVNWzm+r1zprI7t5MwqLq7x+VKTz9l9J9pEdrFKoOw2XVoa3ZZEfdW8hhQWl+DNrhnbyM06kRv74OgdXi0RycrLYTZLEFlG0XuHTiOR1J2hrXJ7OLWgmQlZq+UXo7qLbQcyB2E7As/IKdUoeZnsjKFWTt2yFE877dTuQMbju1VaKi8LsVHuG71DTw5ZJTmTlctEtZCWlvLL5tgM5nbfiagS6WQCG1vHQY8aIoXFBURM+qKNzY21caPOH5v0S/aMWNYAqF2HdXKN2Hcoq2xqPRQXWyfr4xUYvEn/eJIY8ma65LHa8Ox0bMekzPN+9QY4GQOudkASVQJl902zJRyRgYxnOVXUSilyqFF/ixczdtNNxmXUa39mz+Sn/5KeDLGjPPEokXqTXj1/L562bWfCRBYWj3BbYXE7m6cXCot6FBQYrwub5R7RJk0z+53TJYZYT3cn14hdGpGRTVe715Be/ThJrqYV+FYRX2b3FE0SxjNgWykXRtEpRoj2qdh26UQx5rVGGSmMRsu8dg4evw7tezYLzzXyWVu5Un+rDFnPoB7qDF2k/QU9GZ2e1UH7Tng2lFX3E7KLXhuwkmVOl5K9hBQWybjtQS66i7LTY9gwvtk3Y3wzCu3vZA0kMpdRGJMrGI0GBiMlQkRgiCiSRtiZUVkN2FVVSrsRrROnZVSPRo2ifbFElAaznZF53p/TssuqMxUR5UqGPxnvMWeOWH4f1cHWq/LZOXjDvK2WivS27TByMuZB1I9PxIroNaSwSMQNE7C2sViZpdUj1l/CrYywemUS+Z2IZcRsIJG9jCLTudRofdtM0XBixRAVKryDeezs0WjAXrVKbEbHg933ofqMiSasUwdTGTmKeJ1iQyFFyVu+XCyCircMVsoVT8i6rMOOz4WIlceJw6vdgyfSUIV3qUiNDjXygTPaay32XYv4pfCmExBpWzIhhUUSbi4FGVkzjBoxb5ihrEO1+oj+jtf3RHWmc+oLw7t3khumZ6uQ5dh3bDYzFl3GMUJEwTabPVpFudm5poz34UbkjBlmShyvA6ZRmLCbVFXJz0Lsx6G2e78y1YpY4ior5fnbmMmMggJ+q7/eEr6oU7vIpq52IIVFEm6ur+pptnZm2NrcJLNnM9a4sZzy2TXV8uQA4Jldyl53leXDEvusooqGkbCT4RjHq2Bb1Z0TRZhXMaiqcs9KKFpvRlhFMFll79XWtx2zu5OZrmzZpfbD2HfmVjoGvXozUvjdWrIXtaTKrPOCgholzexdmMlHo++N2qPVRJNnU1c7kMIiCdmJopKSGJswwThRlowZtiyHQLsKi17+FB4nUj1kr7vKXt4Tyc1hNWDKCD0UEZhGdSc7Msurd+G039ipB63lxE6YrNX9nfgy2ZVd2dn6Sc60lkBVieL1VbF78C5XuJHQT69NW00oZTpjq+/CrD2pComR1clsQqA3kZKxqasdSGGRhFsWFj1znKyBz2mZ1YYsGvbolqe5iIMh7/Wczuy1zyorx4GM989blqIi5Xy9UEqZkVlGuB11py2TXcuGqOVEZuioDF8mJ3JAm+TMbLLhpqIwbRq/LHE70ojXkupH+LXeko+I1WnwYOX9vvMO/z1ly3lSWCThtmC1Ew5sNfCJLH2YWS5Esm267WkeG0ZYWurMF2DZMmfvTfussgYqGUtgImUxWu6QUSdWyI7YMvrOrmIrUr5QSKlH3j11ePqvDEurE4dbs2VdrcxyU1HQ5jqyWharquJ34D3tNHtl4X1Wr5UWrVOtE6uTqFVVZs4WUlgkwmu6zs5WlntEG4lbMzSr60ycyJ98zKoxO4144EVGyK9TZ8TYdVyZvjZOlsB4kqnFOjDKEpqi70BWrh49H5JmzRi76irxMFGZ5XPSf730ZTK7No+VR2RSI3LYCfHntSg8+qi9sohYL2XUgdOd2b2wOsmCFBbJmC0jqB3Ybvro2HBgWU6mPGFzPLMXMy91GREPvI6FskJ+nXZk7T4davmnTzdvG0Zl03t2O0tgIrlyZKU5Vw870QMycvVofUfUJQurpIZelM+qn1vVlde+TGayiOdZRKKleA87If5WTty8cjb2UBMiilovne69pPZTu+OBW8qk9jllQQqLC1RVmadhdyrktLMaWU6mThITqb934jRrBe8MSpaZnDH7s2c9J7XiYiWhmdFvzBQNs2cXiQ7hdZKV1U55ns0KJ8K0sFDfOsi7r5Pb5XNaBi99mYzKyFsGNbeNnqKYlWUvouiaa8QUJi0i6QV4363dbLFW4wXPhNLpeOCGMumGryIpLC5iNJg4NSObrRt7teSiRcbyi9X1eWdQMpfL7AzYegKPx3F3xQrnz24Gj+k/drdup+3UKH+DKKLCVH0OO8tZdoSs02gpu/3XS18mo75tp43k59e2usbKSt53J7KDtt5745Gfq1aJL7vYUSDMJh88E0qn44GTFAV6bY+ihCTgptMt70xXhoXFzn3dwEpYO00iJGoxEY1+cXJvvUMrIETCcdV9m5w8uxl2FDm77dQNpVlkKUvrMyGjj8kqn9WhjXYRXf60O7O2YyHSLnXKUOqNWLFCXu4Wo2Ux3npevFj8PnYUCKfyXNbv+/UTq9/YnF5uTZxJYZGAqIXBrhnZDRObE3gHBW1diHYo0YFWRn4RLVYK2d136z+PnQEzdpCUaS2y4+9gp52KhJiKom07RiGasqJS7DgKquWzs2uu9j2KyhNe3zGjvidqIXLaRgD3rD9O+ogZdvsib+SSUbuRaanmpaqKsRYtxOpXdQFwe+JMCotD7JrsRc3cbpnYnCAa0nn33eIdUnSgFcmLUVDAF/asNyBkZxsv44jWjd5AYOfZZbyrWIErOpjJdLCzwmwwcLqc5fQ5YsPrRTa0tCNPrJQ5PT+R2Ey8dqNNnPg/yPavMatbp+/TjV2MeS1zXsp9O7LLq35PCosDnJrsjUyGPGHEQUBWSKeZILYz0IosxWgPK6uYyAzCTt24aWFxInBXrZK/oaHbOJmdu5XU0GrpRsYSoF1/moICJeeQ3Qy8dpfE3Ihg0qtbGcgOdBB5VyKbKzpFRHZ53e9JYXGArDwIRksKfvqm8CDTZGvU6O0OtHZyHMgUcKJ1Y+bDImtW5zR3i1H+iiBa/5xE76jhqbKx8mlwKk+c+O2o73DiRGdtRJVZvKn4VdkmY1nVandhGTJVVqCDnXdVXCxeXjuIWs697PeksDhApsneDdxWemSHdBoJYjsDrRNlSk95cLtuRJcOnczqZEcSBNH6x5j58oqoEJbVl2QsYxnJExkWCaMke6LvmFfZ1ruX1tLJYy1Vr1VZaVy3eu3W7s7CMtqCnXelWlmCItf98K8hhcUBMk32RthtnG6HGmvvI0thMVPsRAdKp8qUjNkMz9o+z66mspUEvyMRvMIopLxpU7HN3rzqS07liawlWq3Vw0leJStlW7Xm6NU/b2oAHsXdSka5tbOwGXbflayEh1ZYyS6n0Z92IYXFAW45YqnoCUqto5xVqKOdzm23nLx7EtkRxCqiA6XTZEgy6knvHTZuzNjQoWLJ+eJFSRDFreeSoUiXlcnNg8MTLeJEnshaouXdH4j3PehZNqZPF/PXUZckjZKrmdU7rxO+G0pLVZV+/hSZy+l25DpPewyiNZUUFofINtkzZu4vYCU8ZDju2YG3zEZHdrY7g7CT/BjZ2XIy9iaqsuEUtywXTnw5tMfixXL6kshzOvUzkrFE60RR02vrRsoGb1msrm+GiGIgWy4aWYaysuRveyEi10Xao9H7dGp9swspLBKQqYmKWCv0hIcMxz0ng6teXSQlWZdn5UrxuuKlqkqZ3TgRCH6s1yYybloBZc1eRRxHRZ9TPfRM607kiROrotYXxG66e72B0Gjph+dw6v8nuvQiKzyXx/dm0CA57VSk/E77ndkE0AsZSQqLJGR5oIt27Fjh4cRxT9aMd+VKscRZbkVlaAlaiGRdxm0roKwdnu1kNxV5TrM+5kSe6PVjvTwsRu3bbioBWb5sRvcww6i+RPu9jACJqio5S+R2DrPyy0jDYcdhXSaksAQEp2ZstWPLThAmOlCLCC6r5GsykWEu9zrngLbsQV1SslM2t53VRcMyjdq703L6GR5qZsrXy6iqteC4lazRrb6mN0HSbg4qUjYZFhaZ/imAomjyLrebld9JexbxBXJTRpLCEhCcNvJY4WE2MMeG7TrRvLWCUc3oaVbOpCTGJkzwZ+B16oQrU6iJlDl2tpafHwxLj12LnNvpAJyE1GoHbqdOsEFOwGWm0PAun4pOkkTqgleBmzjR/DqrVomFRssIG5YVraUeqqOuSFvUewYn/U70HbslI0lhCQgyU4lbDcyxYXxOrDJ2Z1ZuDrhmAsdJmc06tBtYCVo/lRYnFjne9qbdZM9u+aycV60GJydOsHYGchmC3uqZ9L4X6Rd2l6F5D15/nRUr+K6lPh9PaLSMZXGZClxseD1PWzR6BidWGtF37JaMJIUlINht5GYOcLy5C+xo3k7XrN2aTfIIHK3A1strYKdDy6aqytznAPAuXXfsAGfXKVN7PS8SU8lyhtdbcuC5jp1lSFFBH/tueBKx6fm3iMgbu47+Rtfj3dMr9rlF9z6yCo2WGcIuy4cl9p5WbdrsGdR3bcdiKPqO3crKSwpLQLCzlbpZRxJZ5hG1sMhas5Y98DsNxVy8WBmY3MqrI0JpKV8dOrFC8GCUC8jp++VZnpPh6OxG1FuzZvy+V6KKvUif4LWKqPXoJFpHPfQUNV7FTGbqB5EBNFYJNFoOk+kIzrMMZXYkJxtHThq1aZ5nUBUW0XchKvPdcr4lhSUA8Aq19HRr4aEiooSIro/KMnkWFcmrQ1kCx428Onbg9SOYNs29Mji1ollZC3hC+L1SEo2WSWQ5ost+TjvvRnRCFNvOzBQ+q34je0NXkSUKHiWQV6bNmSOWuNIoD4vRnk3qYScYgfcZ9KzKPO9CpM251W9JYfEZHs1V1bbNZoux34mGZIoM1DLXrGUpACICx06iL68zPPqtsMiwovEMFLyWJDeX4fTed36+WPp+K9TlCKNriS45yI7K4ZUTovUY68QsK9qNt7/zJqS0I9MKChTFwspfSC/TLU99iSKytG/3XYj6AMrut6Sw+IyMEE9ZZnveDiTLwiJTCxcRODy+EX6HEvu9JOTUL4H3vfq9gahTK5KoQJYxSMmOypH5nF71G16ljTchpaw6FfW78kOJc6pEVFXxT6hk91tSWHyGV2BPm2Yc9WJH4BoNKjwdiGcJScSRz+vcB14v79iBJwLCTadbu1Y00bqVkV/CLjIsFXYEctDCZu3IiSBgJfu0CSl5IqdkbGvgp2yRrcSZ4ZVyFAspLD5jR7MXTYrkhj8GzxJSUZF7Qj8WUYETZEHspeAxQsTkrv1bxFogmh/Dr2f0UiB7VW7ePhJ0xV7PYhWbkJI3VFlWniY/ZYtIqLcTnOYosgspLD5jR7NXOxXv7NTJoGKGkbBQd5P22j/BjsDxY8Cxwq/ZixZegVRZac9aIKJsuzVgOrFU+DkoybIGxB6xVlG/d+blxSrvkojjtIw8TX7KFi9lhx8BCq4qLE888QRr1aoVS01NZT169GCbNm0yPf+XX35hd9xxB8vNzWUpKSmsffv27I033oh8/9BDD7Fu3bqxRo0asezsbHbFFVewb775RqhMQVNYGLM30IZC/LufqrtpurGurAoLvXTfLVpYb3yYnKwMerIQFTheJYETwW+/DhU3BZJIRINbOPXTCULiPllKi7oJo59+W7KxGzmorQfeDTCDIlu8lh1eByi4prAsW7aMpaSksGeffZZ9+eWXbPTo0SwzM5MdPHhQ9/zKykrWrVs3dumll7L333+f7dq1i61fv55t2bIlcs7AgQPZwoUL2RdffMG2bNnCLr30UtayZUt29OhR7nK5rbB45X0tcrit6XvtuGhFVZWcnXb9ws1Zkmj7dEsgBUEps2upiM0UrV7L68He6N1oI1f8co4MAjL6kRNrVqJbWFS8bPuuKSw9evRgY8aMifwdDodZixYt2KxZs3TPf/rpp1nbtm3ZyZMnue/xww8/MADs//7v/7h/46bC4jSts/bF8wqapk39TXTml+Mib7mCkAROFLfKbrd9uiGQgrDsxZg9S0VsZJaMdO52sXo3QalnP5ClFIu2kSAvFwZZ7vHgisJSWVnJkpOT2erVq6M+HzFiBBs0aJDuby655BI2fPhwNnr0aNa8eXPWqVMnNnPmTFZlUrM7duxgANjWrVsNzzlx4gQrLy+PHPv27XNFYZGVZEpFxGTuZ6IzGQ6AVkmp7BKUJHB2kF122e3TKUESrCIZY2PLZGVd9LuNBameeQhqmK9oVuEgLhcGoWxOcUVh2b9/PwPANmzYEPX5xIkTWY8ePXR/06FDB5aamspuvvlm9vHHH7Nly5axpk2bshkzZuieHw6H2WWXXcb69OljWpbp06czALUOmQqL7LTO2mvyCBo/E53JDLF0Y1YahCRwdpFVdjfapwyCJFi1vlhqGazKxGNd9Gq/JzOCVM96mPnBOZEJspW1WGXKardvP4lnuWdGYBSW9u3bs8LCwiiLyuzZs1lubq7u+bfddhtr1aoV27dvn2lZvLCwuGV2FRE0fjnMyQyxFBWgvM8cz86EMsoe5GWBIApW2QkU3XQcjsWovQSxno3KpXfYSVWvXt9NZS3IsiXIZbNLYJaE+vXrxy666KKoz9asWcMAsMqYMJIxY8awgoIC9u2334oUizHmjg+Lmw6EQRU0KrxJ5OxuXW+En34D8UYQHFzNcCpY3RDMPNfkrVevrCxWfUKknrwY7ESc9c02A+S5T5BlKMGPq063Y8eOjfwdDodZfn6+odPtlClTWKtWrVg4HI58NnfuXJaXlxf5u7q6mo0ZM4a1aNGCbd++XbRIjDF3FBa3Z7BuCw+n1+eZxaj34HUmNquroPljeIXd9ySrfQZxxuan4ipiXfQrUs9On/CiTquqxLJhq4eT5aGgtV1CHFfDmlNTU9miRYvYV199xW699VaWmZnJDhw4wBhj7MYbb2STJ0+OnL93717WuHFjNnbsWLZt2zb2+uuvs+bNm7MHH3wwcs7tt9/OMjIy2Pr169n3338fOY4dO8ZdLjcUlnhzbNMiSzjxzmKczvaD6o/hNnbekyqkFy9WfAOctM8gWrT8VlyrqvhzIXkRni2jT4jUqRMlgDfpZezhR98mZSc4uJo4bv78+axly5YsJSWF9ejRg3344YeR7/r3789GjhwZdf6GDRtYz549WWpqKmvbtm2tKCE951kAbOHChdxlciusOeiObXrIFvg8HdvpbD/I/hhuYec9yYxq8Fsx0CMoiqufeyGpyLSg8dapXvtq1qwmy7XVchOvoud33w6iol6XodT8EomntVK/BL7TlO9B98eQjZ33JOIbYNU+g6IYxBIUxdVqacOL+pG1Z5doKgWzc8wGdaeO+l717SAq6nUd3vE7CYQlQ4YAu3cDZWXAkiXKv7t2KZ8HjffeA777zvh7xoB9+5TzZJKcDMybp/w/FIr+Tv372muBdu2ACy8Err9e+bd1a6CkBMjL47sP73lBR/Q9hcPAhAnK50ZkZwOLF/O1T7/aiRXffy/3PLskJwPPPFO7LQM1n82dq5znBiUlyvV5sOoTvHU1b555+wKA/fuBoUOV8tm9jxFe9G2zfqR+VlSknEcED1JY4pRwGFi/Hli6VPlX7WB+CvwhQ4CXXgLy86M/LygA7rkHePTR2oOkKgB//FE5T2+AAJTPCwuBvn3ll9sPRN+TlYIBKHWYnw9ccIH1QBoUxSCWICmuansuKIj+vKBA+dytCYs6qFrB2yd46+rnn63PMRvU7b4TL/t2UBV1I4zkfF2lnt8FiAdKShQBom3oBQXKjMQPK4tZefwW+EOGAFdcoXT4779X7tO7t2JZMZrVhELA3XcDc+YA11yj/K0914sZrSzC4ehn79tXv8yi70m2guF3OzGib1+lLe/fr99eQiHle68UV732bPROZcGjnAJK/fD0CZ46bdKET2FR76sO6hdcwH8fPbzu20FV1PUI2rgTCDxaonIdt51ujdZd7SY+kl0edf11xYrgRTaJ+CXEk79QLCKOfKIRaLJ9O4IcARePju4y4fXnKiriv6ZVndqJ7tHzObHanyfWL8jrvh0UHykr6pqfDTndSoAnRbeTxEeyy6MOMitXBkvgizrUxmO4od2IH5GMx7IVjCArBvGsuDrFzQzbRnVqZ/dio/tb3cfPvh1kRT22jFZyPh7kIi+ksEhAxOs9SAmtgmapKC3lK3fsbrnxghMBI/Ke3FAwgtROYvF7cPMLWYOqXv2Z1SlvFBrP/YP87oKsqDMWP1YgmZDCIgGRDQC90Hjj1VKR6AqLUwEj8p7cUDCC0k6IGpwOqnbzjFjl+QnKoO6UICvqdS3FA2P84zc53Zog4nCo54QmG1FHyeRkd8vDyw8/yD0vaDh15BN5T244gQalnfDC69gcz6gRSnpOl3PnmjtdlpQokXeMRX+uRuSZRThp29crrwAvvqhEn4ncPx7ww5mal6A6xAeBEGOxzTo+qaioQEZGBsrLy5Geni7lmuGwkieEx2MfUHK0XHddzW9ldwa1PFYRFLt2BaPjqaxfr+RcsaKsLL4GThXe55szBxg3LljvJt6oa5ETonLESmaJyoi6oBwGjXiV807gHr89sfd4gJtRQrzLQqrJ3820z0Fff9UjHhzdnCDisEjpv+1T1yIn7FAX/R8SkXiU806gTLeSGDIEWLHCXJPVJj5SzbFGCdL0MkSKlscoOZubyaycwJMFV83qGY9JksyeLxZZ7aCuQRlK+YinPCNBIYjJ2eJRznsBLQlx8tJLwNVX1/5cHaBeeklZE5VpjjUjHk21eub87Gxg+HAlcdXf/25s6vfqeZ3cR+/59EhEk67bJPqyoiyonsQI+hJjPMp5O9CSkAtYeZaTOdY64kT9vqiIsexs83pSzZ8TJ3qzs6qMpbyqKsbmzKF2IJu6GDlhh0RffpUJLTEGB1oScgGrTRDrujm2pESxMOltbqiSnKykAJ83Lzr6QA9VhDzyiHtLbNqyy1jKS04GcnL4zk3UduAGFDnBB+/yayLO0kWgJcb4hBQWQdQQ0OuuqzGpquufBw/yXSMRhSrvgM+z6zAPMoWKbOFFg6t81H1q6srmmE6oC/4PTv1O4m0TRBGC6JMjDY8sPq7jxZJQLHpLCMnJ5ksciWiOFcn0KpI9mPdwurRSl/bpiWfqWuSEUxI1IaCMpdtEXWJ0M0LVTShxnMsYJWcy0mbj3Rxr5vwlMltxYxnE6TVlL+WpZvmhQ+N75+mg4SSZWl0k3hIC8uAkKZ6WRLCCxsrkQ4eU3e7t1I2RfA+c069HCpTreGlh4d0UUft3UNI+28FKaxeZrdQFC4tZvcVzOwgKiWo5IMyRuSlgvFtBZVr3jeS7V8EOjPGP3xTWbAORzKY5OQHRTG1iNKPRhnM3bcofStm3r1j2YDNkhQe7mVkycDMUgohTZIdsq7IN0LeCBtXfx0gm8xBbN6LXcqtueMdvcrq1Ae/SQE5OjXNuPA5SvM6ovXvzO0RqoxisSE4G7rlH+b2bEQ9uRlbEOmnHYzsgiCAge+k2Hp2TnQYtaOvGzrW0ct8PZ15SWGyQCOufPPD6pmzYIDbgDxkCrFoFZGWZ33/pUiWk2Quhwiu8EtoDnyACjBty1ypVRdCwkslWaOvG7rW0PomeI381yh/88GGJ1/VPXkQ96UV9NqqqGCsuZqxpU+vfeOW3YHafePXAJ4hEoK7IXTN4ZTJP3di9VqzclwFFCblIXYkCEZ3RiG7ZnpwM3HcfMHWq9W+8ingwuo+s6ASCIOxRV+SuGXas9kZ143QFwI8VBHK6dYDePhSFhYkTYlkXtznXQ60HL/aIIgjCnESXu2ZYyWSgJhxZxahueK6lhxvyjnf8JoXFIYkeBRKvnvQyoQ3lCCJYJLrcNcNKJi9frmwqy1M3Rtcywu8oIVoSckiQkzPJ6NSUrIv2iCKIoBFkues2MmWy0bUKC4Frr1WCC4Ik98nCkqDI3ja9Ls9ogmZhqcvvgnAOtZ/EQOZ79DvTLS0J1WF4kr3VBcuILILkyyNbESXqFtR+iCBCiePqKLRtunzcTCwnAu+O2AShB7UfIt4hhSXBSORt0/3E76yYpIgSTqD2QyQCpLAkGOQg6h5+ZsUkRZRwArUfIhGgKKEEo65sG+AXfkUnkCJKOIHaD5EIkIUlwejbl38jQiJ+IEWUcAK1HyIRIIUlwQiKgyghF1JECSdQ+yESAVJYEhC/HUQJ+ZAiSjiB2g+RCFAelgSGEkQlHnV5HxVCnFgZcOgQcOed1H6IYEGJ4wgiQSFFlODBKEncY4/x7zVDEF5ACgtBCEBKAJFIULZrIp6gTLcEwUlJiZJ6/8ILgeuvV/5t3ZoyfxLxCSWJIxIVUliIOg2lKycSDUoSRyQqpLAQdRaaiRKJCCWJIxIVUliIOgvNRIlEhJLEEYkKKSxEnYVmokQiQkniiESFFBaizkIzUSIRoSRxRKJCCgtRZ6GZKJGoULZrIhGh3ZqJOos6Ex06VFFOtM63NBMl4p0hQ4ArrqD8QkTiQAoLUadRZ6J6GUEpXTkR7yQnAxdc4HcpCEIOpLAQdR6aiRIEQQQfUliIOoleKn6aiRIEQQQXUliIOofRpnDz5tESEEEQRFChKCGiTkGp+AmCIOITUliIOgOl4icIgohfSGEh6gyUip8gCCJ+IYWFqDNQKn6CIIj4hRQWos5AqfgJgiDiF1JYiDoDpeInCIKIX0hhIeoMtCkcQRBE/GJLYXnyySfRunVrpKWloWfPnvjoo49Mzz98+DDGjBmDvLw8pKam4owzzsCaNWscXZMg7ECbwhEEQcQnwonjli9fjrvuugsLFixAz549MXfuXAwcOBDbtm1D8+bNa51/8uRJ/P73v0fz5s3x0ksvIT8/H3v27EFmZqbtaxKEEygVP0EQRPwRYkwvK4UxPXv2RPfu3fHEE08AAKqrq1FYWIhx48Zh8uTJtc5fsGABHnnkEXzzzTeoX7++lGvqUVFRgYyMDJSXlyM9PV3kkQiCIAiC8Ane8VtoSejkyZP45JNPMGDAgJoLJCVhwIAB2Lhxo+5vXn31VfTq1QtjxoxBTk4OOnfujIceegjh/2bnsnNNAKisrERFRUXUQRAEQRBEYiKksBw6dAjhcBg5OTlRn+fk5ODAgQO6v/n222/x0ksvIRwOY82aNbj33nsxe/ZsPPjgg7avCQCzZs1CRkZG5CgsLBR5FIIgCIIg4gjXo4Sqq6vRvHlzPPPMM+jatSuGDRuGqVOnYsGCBY6uO2XKFJSXl0eOffv2SSoxQRAEQRBBQ8jptlmzZkhOTsbBgwejPj948CByc3N1f5OXl4f69esjWePR2LFjRxw4cAAnT560dU0ASE1NRWpqqkjxCYIgCIKIU4QsLCkpKejatSvWrVsX+ay6uhrr1q1Dr169dH/Tp08f7Ny5E9XV1ZHPtm/fjry8PKSkpNi6JkEQBEEQdQvhJaG77roLf//73/Hcc8/h66+/xu23345ff/0VN910EwBgxIgRmDJlSuT822+/HT///DMmTJiA7du344033sBDDz2EMWPGcF+TIAiCIIi6jXAelmHDhuHHH3/EfffdhwMHDuDcc8/FW2+9FXGa3bt3L5KSavSgwsJCvP3227jzzjtx9tlnIz8/HxMmTMCkSZO4r0kQBEEQRN1GOA9LUKE8LARBEAQRf7iSh4UgCIIgCMIPhJeEgopqKKIEcgRBEAQRP6jjttWCT8IoLEeOHAEASiBHEARBEHHIkSNHkJGRYfh9wviwVFdX4z//+Q8aN26MUCgk7boVFRUoLCzEvn37yDfGRaievYHq2Tuorr2B6tkb3KxnxhiOHDmCFi1aRAXtxJIwFpakpCQUFBS4dv309HTqDB5A9ewNVM/eQXXtDVTP3uBWPZtZVlTI6ZYgCIIgiMBDCgtBEARBEIGHFBYLUlNTMX36dNq3yGWonr2B6tk7qK69gerZG4JQzwnjdEsQBEEQROJCFhaCIAiCIAIPKSwEQRAEQQQeUlgIgiAIggg8pLAQBEEQBBF4SGEhCIIgCCLwkMJiwpNPPonWrVsjLS0NPXv2xEcffeR3keKKWbNmoXv37mjcuDGaN2+OwYMHY9u2bVHnnDhxAmPGjEFWVhYaNWqEq666CgcPHow6Z+/evbjsssvQsGFDNG/eHBMnTkRVVZWXjxJX/PWvf0UoFEJRUVHkM6pnOezfvx833HADsrKy0KBBA3Tp0gUff/xx5HvGGO677z7k5eWhQYMGGDBgAHbs2BF1jZ9//hnDhw9Heno6MjMzccstt+Do0aNeP0qgCYfDuPfee9GmTRs0aNAA7dq1wwMPPBC1OR7VtTj//Oc/cfnll6NFixYIhUJ4+eWXo76XVaf/+te/0LdvX6SlpaGwsBAPP/ywnAdghC7Lli1jKSkp7Nlnn2VffvklGz16NMvMzGQHDx70u2hxw8CBA9nChQvZF198wbZs2cIuvfRS1rJlS3b06NHIObfddhsrLCxk69atYx9//DH77W9/y3r37h35vqqqinXu3JkNGDCAffbZZ2zNmjWsWbNmbMqUKX48UuD56KOPWOvWrdnZZ5/NJkyYEPmc6tk5P//8M2vVqhUbNWoU27RpE/v222/Z22+/zXbu3Bk5569//SvLyMhgL7/8Mvv888/ZoEGDWJs2bdjx48cj51x88cXsnHPOYR9++CF777332Omnn86uu+46Px4psMycOZNlZWWx119/ne3atYutXLmSNWrUiM2bNy9yDtW1OGvWrGFTp05lJSUlDABbvXp11Pcy6rS8vJzl5OSw4cOHsy+++IItXbqUNWjQgP3tb39zXH5SWAzo0aMHGzNmTOTvcDjMWrRowWbNmuVjqeKbH374gQFg//d//8cYY+zw4cOsfv36bOXKlZFzvv76awaAbdy4kTGmdLCkpCR24MCByDlPP/00S09PZ5WVld4+QMA5cuQIa9++PVu7di3r379/RGGhepbDpEmT2Pnnn2/4fXV1NcvNzWWPPPJI5LPDhw+z1NRUtnTpUsYYY1999RUDwDZv3hw5580332ShUIjt37/fvcLHGZdddhm7+eaboz4bMmQIGz58OGOM6loGsQqLrDp96qmnWJMmTaLkxqRJk1iHDh0cl5mWhHQ4efIkPvnkEwwYMCDyWVJSEgYMGICNGzf6WLL4pry8HADQtGlTAMAnn3yCU6dORdXzmWeeiZYtW0bqeePGjejSpQtycnIi5wwcOBAVFRX48ssvPSx98BkzZgwuu+yyqPoEqJ5l8eqrr6Jbt264+uqr0bx5c5x33nn4+9//Hvl+165dOHDgQFQ9Z2RkoGfPnlH1nJmZiW7dukXOGTBgAJKSkrBp0ybvHibg9O7dG+vWrcP27dsBAJ9//jnef/99XHLJJQCort1AVp1u3LgR/fr1Q0pKSuScgQMHYtu2bfjll18clTFhdmuWyaFDhxAOh6OENwDk5OTgm2++8alU8U11dTWKiorQp08fdO7cGQBw4MABpKSkIDMzM+rcnJwcHDhwIHKO3ntQvyMUli1bhk8//RSbN2+u9R3Vsxy+/fZbPP3007jrrrvwl7/8BZs3b8b48eORkpKCkSNHRupJrx619dy8efOo7+vVq4emTZtSPWuYPHkyKioqcOaZZyI5ORnhcBgzZ87E8OHDAYDq2gVk1emBAwfQpk2bWtdQv2vSpIntMpLCQnjCmDFj8MUXX+D999/3uygJx759+zBhwgSsXbsWaWlpfhcnYamurka3bt3w0EMPAQDOO+88fPHFF1iwYAFGjhzpc+kSixUrVuDFF1/EkiVL0KlTJ2zZsgVFRUVo0aIF1XUdhpaEdGjWrBmSk5NrRVEcPHgQubm5PpUqfhk7dixef/11lJWVoaCgIPJ5bm4uTp48icOHD0edr63n3Nxc3fegfkcoSz4//PADfvOb36BevXqoV68e/u///g+PP/446tWrh5ycHKpnCeTl5eGss86K+qxjx47Yu3cvgJp6MpMbubm5+OGHH6K+r6qqws8//0z1rGHixImYPHkyrr32WnTp0gU33ngj7rzzTsyaNQsA1bUbyKpTN2UJKSw6pKSkoGvXrli3bl3ks+rqaqxbtw69evXysWTxBWMMY8eOxerVq/Huu+/WMhN27doV9evXj6rnbdu2Ye/evZF67tWrF7Zu3RrVSdauXYv09PRag0dd5aKLLsLWrVuxZcuWyNGtWzcMHz488n+qZ+f06dOnVlj+9u3b0apVKwBAmzZtkJubG1XPFRUV2LRpU1Q9Hz58GJ988knknHfffRfV1dXo2bOnB08RHxw7dgxJSdHDU3JyMqqrqwFQXbuBrDrt1asX/vnPf+LUqVORc9auXYsOHTo4Wg4CQGHNRixbtoylpqayRYsWsa+++ordeuutLDMzMyqKgjDn9ttvZxkZGWz9+vXs+++/jxzHjh2LnHPbbbexli1bsnfffZd9/PHHrFevXqxXr16R79Vw2z/84Q9sy5Yt7K233mLZ2dkUbmuBNkqIMapnGXz00UesXr16bObMmWzHjh3sxRdfZA0bNmSLFy+OnPPXv/6VZWZmsldeeYX961//YldccYVuWOh5553HNm3axN5//33Wvn37Oh1qq8fIkSNZfn5+JKy5pKSENWvWjP2///f/IudQXYtz5MgR9tlnn7HPPvuMAWCPPfYY++yzz9iePXsYY3Lq9PDhwywnJ4fdeOON7IsvvmDLli1jDRs2pLBmt5k/fz5r2bIlS0lJYT169GAffvih30WKKwDoHgsXLoycc/z4cXbHHXewJk2asIYNG7Irr7ySff/991HX2b17N7vkkktYgwYNWLNmzdjdd9/NTp065fHTxBexCgvVsxxee+011rlzZ5aamsrOPPNM9swzz0R9X11dze69916Wk5PDUlNT2UUXXcS2bdsWdc5PP/3ErrvuOtaoUSOWnp7ObrrpJnbkyBEvHyPwVFRUsAkTJrCWLVuytLQ01rZtWzZ16tSoUFmqa3HKysp0ZfLIkSMZY/Lq9PPPP2fnn38+S01NZfn5+eyvf/2rlPKHGNOkDiQIgiAIgggg5MNCEARBEETgIYWFIAiCIIjAQwoLQRAEQRCBhxQWgiAIgiACDyksBEEQBEEEHlJYCIIgCIIIPKSwEARBEAQReEhhIQiCIAgi8JDCQhAEQRBE4CGFhSAIgiCIwEMKC0EQBEEQgef/A9Wky+/yojeDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "# Plot the training history\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step\n",
      "[[0.36019167]\n",
      " [0.36019167]\n",
      " [0.36019164]\n",
      " [0.36019164]\n",
      " [0.36019164]\n",
      " [0.36019164]\n",
      " [0.36019164]\n",
      " [0.36019164]\n",
      " [0.36019164]]\n",
      "[0 0 0 0 1 1 1 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot predictions against actual values\n",
    "predictions = model.predict(xTest)\n",
    "\n",
    "xLabel = range(len(xTest))\n",
    "\n",
    "print(predictions)\n",
    "print(yTest)\n",
    "\n",
    "plt.clf()\n",
    "plt.title(\"Comparison of predictions to actual values\")\n",
    "plt.plot(xLabel, yTest, 'r.', label='Actual')\n",
    "plt.plot(xLabel, predictions, 'b', label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ducma\\AppData\\Local\\Temp\\tmpvcix70am\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ducma\\AppData\\Local\\Temp\\tmpvcix70am\\assets\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40992"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Keras model to a tflite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(tflite_model_name + '.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "  c_str = ''\n",
    "\n",
    "  # Create header guard\n",
    "  c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "  c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "  # Add array length at top of file\n",
    "  c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "  # Declare C variable\n",
    "  c_str += 'unsigned char ' + var_name + '[] = {'\n",
    "  hex_array = []\n",
    "  for i, val in enumerate(hex_data) :\n",
    "\n",
    "    # Construct string from hex\n",
    "    hex_str = format(val, '#04x')\n",
    "\n",
    "    # Add formatting so each line stays within 80 characters\n",
    "    if (i + 1) < len(hex_data):\n",
    "      hex_str += ','\n",
    "    if (i + 1) % 12 == 0:\n",
    "      hex_str += '\\n '\n",
    "    hex_array.append(hex_str)\n",
    "\n",
    "  # Add closing brace\n",
    "  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "  # Close out header guard\n",
    "  c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "  return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "  file.write(hex_to_c_array(tflite_model, c_model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
